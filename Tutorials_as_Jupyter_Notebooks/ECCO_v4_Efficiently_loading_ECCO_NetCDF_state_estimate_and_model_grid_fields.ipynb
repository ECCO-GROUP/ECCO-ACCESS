{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Efficiently loading ECCO NetCDF state estimate and model grid fields\n",
    "\n",
    "## Objectives\n",
    "\n",
    "Introduce routines for loading multiple ECCO NetCDF files at once.\n",
    "\n",
    "## Introduction \n",
    "\n",
    "ECCOv4 NetCDF output fields are available in two formats.   \n",
    "\n",
    "\n",
    "### Format 1: output frequency / variable name / year / month or day / tile\n",
    "\n",
    "The first divides the output into small chunks, one file per llc90 tile and output time freqency.  For example:\n",
    "\n",
    "* /eccov4r3_native_grid_netcdf_tiles/mon_mean/**VARIABLE_NAME**/year/month/**VARIABLE_NAME**\\_tile_**NN**.nc\n",
    "* /eccov4r3_native_grid_netcdf_tiles/mon_snapshot/**VARIABLE_NAME**/year/month/**VARIABLE_NAME**\\_tile_**NN**.nc\n",
    "* /eccov4r3_native_grid_netcdf_tiles/day_mean/**VARIABLE_NAME**/year/day/**VARIABLE_NAME**\\_tile_**NN**.nc\n",
    "* /eccov4r3_native_grid_netcdf_tiles/grid/\n",
    "\n",
    "Where **VARIABLE_NAME** is the MITgcm name of the variable such as ``THETA`` or ``SALT`` and **NN** is the tile number [0, 1, ..., 12] \n",
    "\n",
    "In this format, 3D monthly-mean and monthly-snapshot fields are about 3mb and 2D fields are about 130kb\n",
    "\n",
    "\n",
    "### Format 2: output frequency / variable name / year\n",
    "\n",
    "The second format combines the tiles and months or days together for a given year:\n",
    "\n",
    "* /eccov4r3_native_grid_netcdf/mon_mean/**VARIABLE_NAME**/**VARIABLE_NAME**\\_**YYYY**.nc\n",
    "* /eccov4r3_native_grid_netcdf/mon_snapshot/**VARIABLE_NAME**/**VARIABLE_NAME**\\_**YYYY**.nc\n",
    "* /eccov4r3_native_grid_netcdf/day_mean/**VARIABLE_NAME**/**VARIABLE_NAME**\\_**YYYY**.nc\n",
    "* /eccov4r3_native_grid_netcdf/grid/ECCOv4r3_grid.nc\n",
    "\n",
    "Where **YYYY** is year of interest [1992..2015]\n",
    "\n",
    "In this format, 3D (monthly-mean and monthly-snapshot) fields are about 265mb, 2D monthly-mean fields are 6mb, 2D daily-mean fields are about 150mb.\n",
    "\n",
    "\n",
    "### Which format to use?\n",
    "\n",
    "The choice of whether to work with many small files (format 1) or fewer large files depends on the analysis tools that you have available.  \n",
    "\n",
    "The advantages of *Format 1* is that they don't require a machine with very much memory.  Small slices of the state estimate can be read and operated upon sequentially.  This may be helpful if you only need to analyze a small area or short time interval.  Each individual I/O operation is fast and the memory footprint is small but the I/O time per data element read is high.\n",
    "\n",
    "The advantages of *Format 2* is that the I/O time per data element is smaller but this can come at the cost of higher memory required.  Loading one year of 3D field of potential temperature, salinity, velocity (u, v, w) costs 5x265 mb = 1.3gb of ram.  \n",
    "\n",
    "However, if your analysis tool **doesn't require that you actually load the entire NetCDF file into memory** before then loading multiple fields in *Format 2* is by far the best choice.  Fortunately, the ``ecco_v4_py`` Python package leverages the ``xarray`` and ``Dask`` Python packages which enable just this capability.\n",
    "\n",
    "Regardless of which format you prefer to use, this tutorial we will show you how to load multiple files simultaneously!\n",
    "\n",
    "## Loading ECCO NetCDF files from tiles (Format 1)\n",
    "\n",
    "\n",
    "So far in the previous tutorials we've loaded NetCDF files one tile at a time.  For example:\n",
    "\n",
    "```\n",
    "vvel_dataset = xr.open_dataset(data_dir + fname).load()\n",
    "```\n",
    "\n",
    "Two routines in the ``ecco_v4_py`` package faciliate loading and combining the 13 tile files of variables or model grid parameters located in a single directory.\n",
    "\n",
    "1. `load_ecco_var_from_tiles_nc` \n",
    "2. `load_ecco_grid_from_tiles_nc`\n",
    "\n",
    "And a third faciliates loading tile files of variables across multiple directories (times).\n",
    "\n",
    "3. `recursive_load_ecco_var_from_tiles_nc`\n",
    "\n",
    "These methods automate the loading of all 13 tiles.\n",
    "Let's jump right in and use `load_ecco_grid_from_tiles_nc` to load all 13 GRID tile files.  \n",
    "\n",
    "### Loading model grid fields with ``load_ecco_grid_from_tiles_nc``\n",
    "\n",
    "First let's set up our environment..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append('/Users/ifenty/ECCOv4-py')\n",
    "import ecco_v4_py as ecco\n",
    "\n",
    "# define a high-level directory for ECCO fields\n",
    "ECCO_tiles_dir = '/Users/ifenty/eccov4r3_native_grid_netcdf_tiles/'\n",
    "\n",
    "# Load one tile of the llc90 grid\n",
    "grid_dir= ECCO_tiles_dir + 'grid'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use our new routine to load all the ``grid`` files.  This routine loads each tile and concatenates them along a new *dimension* called $tile$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid_all_tiles = ecco.load_ecco_grid_from_tiles_nc(grid_dir).load()\n",
    "grid_all_tiles.attrs = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at `grid_all_tiles`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:  (i: 90, i_g: 90, j: 90, j_g: 90, k: 50, k_l: 50, k_p1: 51, k_u: 50, tile: 13)\n",
       "Coordinates:\n",
       "  * k_p1     (k_p1) int64 0 1 2 3 4 5 6 7 8 9 ... 41 42 43 44 45 46 47 48 49 50\n",
       "  * j_g      (j_g) int64 0 1 2 3 4 5 6 7 8 9 ... 80 81 82 83 84 85 86 87 88 89\n",
       "  * i_g      (i_g) int64 0 1 2 3 4 5 6 7 8 9 ... 80 81 82 83 84 85 86 87 88 89\n",
       "  * k        (k) int64 0 1 2 3 4 5 6 7 8 9 10 ... 40 41 42 43 44 45 46 47 48 49\n",
       "  * j        (j) int64 0 1 2 3 4 5 6 7 8 9 10 ... 80 81 82 83 84 85 86 87 88 89\n",
       "  * k_u      (k_u) int64 0 1 2 3 4 5 6 7 8 9 ... 40 41 42 43 44 45 46 47 48 49\n",
       "  * i        (i) int64 0 1 2 3 4 5 6 7 8 9 10 ... 80 81 82 83 84 85 86 87 88 89\n",
       "  * k_l      (k_l) int64 0 1 2 3 4 5 6 7 8 9 ... 40 41 42 43 44 45 46 47 48 49\n",
       "    Zl       (k_l) float32 0.0 -10.0 -20.0 -30.0 ... -4834.0 -5244.5 -5678.0\n",
       "    Zu       (k_u) float32 -10.0 -20.0 -30.0 -40.0 ... -5244.5 -5678.0 -6134.5\n",
       "    Z        (k) float32 -5.0 -15.0 -25.0 -35.0 ... -5039.25 -5461.25 -5906.25\n",
       "    Zp1      (k_p1) float32 0.0 -10.0 -20.0 -30.0 ... -5244.5 -5678.0 -6134.5\n",
       "    PHrefC   (k) float32 49.05 147.15 245.25 ... 49435.043 53574.863 57940.312\n",
       "    drC      (k_p1) float32 5.0 10.0 10.0 10.0 10.0 ... 399.0 422.0 445.0 228.25\n",
       "    PHrefF   (k_p1) float32 0.0 98.1 196.2 ... 51448.547 55701.18 60179.445\n",
       "    drF      (k) float32 10.0 10.0 10.0 10.0 10.0 ... 387.5 410.5 433.5 456.5\n",
       "  * tile     (tile) int64 0 1 2 3 4 5 6 7 8 9 10 11 12\n",
       "    XC       (tile, j, i) float32 -111.60647 -111.303 ... -105.58465 -111.86579\n",
       "    YC       (tile, j, i) float32 -88.24259 -88.382515 ... -88.07871 -88.10267\n",
       "    XG       (tile, j_g, i_g) float32 -115.0 -115.0 ... -102.928925 -108.95171\n",
       "    YG       (tile, j_g, i_g) float32 -88.17569 -88.31587 ... -87.9892 -88.02409\n",
       "    dxC      (tile, j, i_g) float32 15583.418 15588.104 ... 23865.428 23406.256\n",
       "    rAs      (tile, j_g, i) float32 179944260.0 180486990.0 ... 364150620.0\n",
       "    rAw      (tile, j, i_g) float32 361699460.0 362790240.0 ... 364760350.0\n",
       "    Depth    (tile, j, i) float32 0.0 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0 0.0\n",
       "    rA       (tile, j, i) float32 362256450.0 363300960.0 ... 361119100.0\n",
       "    dxG      (tile, j_g, i) float32 15584.907 15589.316 ... 23600.436 23142.107\n",
       "    dyG      (tile, j, i_g) float32 23210.262 23273.26 ... 15595.26 15583.685\n",
       "    rAz      (tile, j_g, i_g) float32 179944260.0 180486990.0 ... 364150620.0\n",
       "    dyC      (tile, j_g, i) float32 11563.718 11593.785 ... 15585.765 15578.138\n",
       "    hFacS    (tile, k, j_g, i) float32 0.0 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0\n",
       "    hFacC    (tile, k, j, i) float32 0.0 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0 0.0\n",
       "    hFacW    (tile, k, j, i_g) float32 0.0 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0\n",
       "Data variables:\n",
       "    *empty*"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_all_tiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examining the ``grid_all_tiles`` ``Dataset`` object\n",
    "\n",
    "##### 1. Dimensions\n",
    "`Dimensions:  (i: 90, i_g: 90, j: 90, j_g: 90, k: 50, k_l: 50, k_p1: 51, k_u: 50, tile: 13)`\n",
    "\n",
    "The *Dimensions* list includes a new dimension, **tile** of length 13.\n",
    "\n",
    "##### 2. Dimension Coordinates\n",
    "```\n",
    "Coordinates:\n",
    "  * k_p1     (k_p1) int64 0 1 2 3 4 5 6 7 8 9 ... 41 42 43 44 45 46 47 48 49 50\n",
    "  * j_g      (j_g) int64 0 1 2 3 4 5 6 7 8 9 ... 80 81 82 83 84 85 86 87 88 89\n",
    "  * i_g      (i_g) int64 0 1 2 3 4 5 6 7 8 9 ... 80 81 82 83 84 85 86 87 88 89\n",
    "  * k        (k) int64 0 1 2 3 4 5 6 7 8 9 10 ... 40 41 42 43 44 45 46 47 48 49\n",
    "  * j        (j) int64 0 1 2 3 4 5 6 7 8 9 10 ... 80 81 82 83 84 85 86 87 88 89\n",
    "  * k_u      (k_u) int64 0 1 2 3 4 5 6 7 8 9 ... 40 41 42 43 44 45 46 47 48 49\n",
    "  * i        (i) int64 0 1 2 3 4 5 6 7 8 9 10 ... 80 81 82 83 84 85 86 87 88 89\n",
    "  * k_l      (k_l) int64 0 1 2 3 4 5 6 7 8 9 ... 40 41 42 43 44 45 46 47 48 49\n",
    "  * tile     (tile) int64 0 1 2 3 4 5 6 7 8 9 10 11 12\n",
    "``` \n",
    "\n",
    "Notice that **tile** coordinate now appears as an integer array: 0 .. 12.\n",
    "\n",
    "\n",
    "##### 3. Non-Dimension Spatial Coordinates\n",
    "```\n",
    "Coordinates:\n",
    "    Zl       (k_l) float32 0.0 -10.0 -20.0 -30.0 ... -4834.0 -5244.5 -5678.0\n",
    "    Zu       (k_u) float32 -10.0 -20.0 -30.0 -40.0 ... -5244.5 -5678.0 -6134.5\n",
    "    Z        (k) float32 -5.0 -15.0 -25.0 -35.0 ... -5039.25 -5461.25 -5906.25\n",
    "    Zp1      (k_p1) float32 0.0 -10.0 -20.0 -30.0 ... -5244.5 -5678.0 -6134.5\n",
    "    PHrefC   (k) float32 49.05 147.15 245.25 ... 49435.043 53574.863 57940.312\n",
    "    PHrefF   (k_p1) float32 0.0 98.1 196.2 ... 51448.547 55701.18 60179.445\n",
    "    drF      (k) float32 10.0 10.0 10.0 10.0 10.0 ... 387.5 410.5 433.5 456.5\n",
    "    XC       (tile, j, i) float32 -111.60647 -111.303 ... -105.58465 -111.86579\n",
    "    YC       (tile, j, i) float32 -88.24259 -88.382515 ... -88.07871 -88.10267\n",
    "    XG       (tile, j_g, i_g) float32 -115.0 -115.0 ... -102.928925 -108.95171\n",
    "    YG       (tile, j_g, i_g) float32 -88.17569 -88.31587 ... -87.9892 -88.02409\n",
    "```\n",
    "\n",
    "The non-dimension spatial coordinates that associated with depth are the same as when we loaded one tile at a time.  This makes sense because the model vertical grid is not a function of space.  \n",
    "\n",
    "On the other hand, the latitude and longitude fields (XC,YC and XG,YG) now have **tile** as a new dimension indicating that the latitudes and longitudes are different for each tile.\n",
    "\n",
    "To demonstrate, let's plot the latitudes and longitudes of two tiles, tile 6 (Arctic cap) and tile 2 (NE Atlantic and SE Atlantic). \n",
    "\n",
    "> **Note:** *Don't wory about the fancy Python below, you'll see how all of this works in later tutorials. They key is to notice that we are first **sel**ecting tile 6 and then **sel**ting tile 2.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:  (i: 90, i_g: 90, j: 90, j_g: 90, k: 50, k_l: 50, k_p1: 51, k_u: 50, tile: 13)\n",
       "Coordinates:\n",
       "  * k_p1     (k_p1) int64 0 1 2 3 4 5 6 7 8 9 ... 41 42 43 44 45 46 47 48 49 50\n",
       "  * j_g      (j_g) int64 0 1 2 3 4 5 6 7 8 9 ... 80 81 82 83 84 85 86 87 88 89\n",
       "  * i_g      (i_g) int64 0 1 2 3 4 5 6 7 8 9 ... 80 81 82 83 84 85 86 87 88 89\n",
       "  * k        (k) int64 0 1 2 3 4 5 6 7 8 9 10 ... 40 41 42 43 44 45 46 47 48 49\n",
       "  * j        (j) int64 0 1 2 3 4 5 6 7 8 9 10 ... 80 81 82 83 84 85 86 87 88 89\n",
       "  * k_u      (k_u) int64 0 1 2 3 4 5 6 7 8 9 ... 40 41 42 43 44 45 46 47 48 49\n",
       "  * i        (i) int64 0 1 2 3 4 5 6 7 8 9 10 ... 80 81 82 83 84 85 86 87 88 89\n",
       "  * k_l      (k_l) int64 0 1 2 3 4 5 6 7 8 9 ... 40 41 42 43 44 45 46 47 48 49\n",
       "    Zl       (k_l) float32 0.0 -10.0 -20.0 -30.0 ... -4834.0 -5244.5 -5678.0\n",
       "    Zu       (k_u) float32 -10.0 -20.0 -30.0 -40.0 ... -5244.5 -5678.0 -6134.5\n",
       "    Z        (k) float32 -5.0 -15.0 -25.0 -35.0 ... -5039.25 -5461.25 -5906.25\n",
       "    Zp1      (k_p1) float32 0.0 -10.0 -20.0 -30.0 ... -5244.5 -5678.0 -6134.5\n",
       "    PHrefC   (k) float32 49.05 147.15 245.25 ... 49435.043 53574.863 57940.312\n",
       "    drC      (k_p1) float32 5.0 10.0 10.0 10.0 10.0 ... 399.0 422.0 445.0 228.25\n",
       "    PHrefF   (k_p1) float32 0.0 98.1 196.2 ... 51448.547 55701.18 60179.445\n",
       "    drF      (k) float32 10.0 10.0 10.0 10.0 10.0 ... 387.5 410.5 433.5 456.5\n",
       "  * tile     (tile) int64 0 1 2 3 4 5 6 7 8 9 10 11 12\n",
       "    XC       (tile, j, i) float32 -111.60647 -111.303 ... -105.58465 -111.86579\n",
       "    YC       (tile, j, i) float32 -88.24259 -88.382515 ... -88.07871 -88.10267\n",
       "    XG       (tile, j_g, i_g) float32 -115.0 -115.0 ... -102.928925 -108.95171\n",
       "    YG       (tile, j_g, i_g) float32 -88.17569 -88.31587 ... -87.9892 -88.02409\n",
       "    dxC      (tile, j, i_g) float32 15583.418 15588.104 ... 23865.428 23406.256\n",
       "    rAs      (tile, j_g, i) float32 179944260.0 180486990.0 ... 364150620.0\n",
       "    rAw      (tile, j, i_g) float32 361699460.0 362790240.0 ... 364760350.0\n",
       "    Depth    (tile, j, i) float32 0.0 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0 0.0\n",
       "    rA       (tile, j, i) float32 362256450.0 363300960.0 ... 361119100.0\n",
       "    dxG      (tile, j_g, i) float32 15584.907 15589.316 ... 23600.436 23142.107\n",
       "    dyG      (tile, j, i_g) float32 23210.262 23273.26 ... 15595.26 15583.685\n",
       "    rAz      (tile, j_g, i_g) float32 179944260.0 180486990.0 ... 364150620.0\n",
       "    dyC      (tile, j_g, i) float32 11563.718 11593.785 ... 15585.765 15578.138\n",
       "    hFacS    (tile, k, j_g, i) float32 0.0 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0\n",
       "    hFacC    (tile, k, j, i) float32 0.0 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0 0.0\n",
       "    hFacW    (tile, k, j, i_g) float32 0.0 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0\n",
       "Data variables:\n",
       "    *empty*"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_all_tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(10, 10))\n",
    "# create a subplot to the left to plot longitude\n",
    "fig = plt.subplot(221)\n",
    "# mask out the land in the latitude field\n",
    "YC_masked = grid_all_tiles.YC.where(grid_all_tiles.hFacC.sel(k=0) != 0, np.nan)\n",
    "# select out tile 6 and plot using the 'jet' colormap\n",
    "YC_masked.sel(tile=6).plot(cmap='jet')\n",
    "\n",
    "# repeat with longitude\n",
    "plt.subplot(222)\n",
    "XC_masked = grid_all_tiles.XC.where(grid_all_tiles.hFacC.sel(k=0) != 0, np.nan)\n",
    "XC_masked.sel(tile=6).plot(cmap='jet')\n",
    "\n",
    "# push the subplots away from each other a bit\n",
    "plt.subplots_adjust(bottom=0, right=1.2, top=.9)\n",
    "plt.suptitle('Latitude and Longitude of Tile 6 (Arctic Tile)', fontsize=18);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(10, 10))\n",
    "\n",
    "#  tile 2 latitude \n",
    "plt.subplot(221)\n",
    "YC_masked = grid_all_tiles.YC.where(grid_all_tiles.hFacC.sel(k=0) != 0, np.nan)\n",
    "YC_masked.sel(tile=2).plot(cmap='jet')\n",
    "\n",
    "#  tile 2 longitude\n",
    "plt.subplot(222)\n",
    "XC_masked = grid_all_tiles.XC.where(grid_all_tiles.hFacC.sel(k=0) != 0, np.nan)\n",
    "XC_masked.sel(tile=2).plot(cmap='jet')\n",
    "\n",
    "plt.subplots_adjust(bottom=0, right=1.2, top=.9)\n",
    "plt.suptitle('Latitude and Longitude of Tile 2 (NE Atlantic)', fontsize=18);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly XC and YC vary as a function of tile!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Grid Geometry Parameters and Ancillary Information\n",
    "```\n",
    "Coordinates:\n",
    "    dxC      (tile, j, i_g) float32 15583.418 15588.104 ... 23865.428 23406.256\n",
    "    rAs      (tile, j_g, i) float32 179944260.0 180486990.0 ... 364150620.0\n",
    "    rAw      (tile, j, i_g) float32 361699460.0 362790240.0 ... 364760350.0\n",
    "    Depth    (tile, j, i) float32 0.0 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0 0.0\n",
    "    rA       (tile, j, i) float32 362256450.0 363300960.0 ... 361119100.0\n",
    "    dxG      (tile, j_g, i) float32 15584.907 15589.316 ... 23600.436 23142.107\n",
    "    dyG      (tile, j, i_g) float32 23210.262 23273.26 ... 15595.26 15583.685\n",
    "    rAz      (tile, j_g, i_g) float32 179944260.0 180486990.0 ... 364150620.0\n",
    "    dyC      (tile, j_g, i) float32 11563.718 11593.785 ... 15585.765 15578.138\n",
    "    hFacS    (tile, k, j_g, i) float32 0.0 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0\n",
    "    hFacC    (tile, k, j, i) float32 0.0 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0 0.0\n",
    "    hFacW    (tile, k, j, i_g) float32 0.0 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0\n",
    "```\n",
    "\n",
    "llc90 grid cell geometries vary with tile.  For example, consider grid cell areas of tile 1 (SE Atlantic) and tile 2 (NE Atlantic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(10, 10))\n",
    "\n",
    "#  tile 6 grid cell area (m^2)\n",
    "plt.subplot(221)\n",
    "rA_masked_6 = grid_all_tiles.rA.where(grid_all_tiles.hFacC.sel(k=0) != 0, np.nan)\n",
    "rA_masked_6.sel(tile=1).plot(cmap='jet', vmin=1e9, vmax=1.2e10)\n",
    "\n",
    "#  tile 1 grid cell area (m^2)\n",
    "plt.subplot(222)\n",
    "rA_masked_1 = grid_all_tiles.rA.where(grid_all_tiles.hFacC.sel(k=0) != 0, np.nan)\n",
    "rA_masked_1.sel(tile=2).plot(cmap='jet', vmin=1e9, vmax=1.2e10)\n",
    "\n",
    "plt.subplots_adjust(bottom=0, right=1.2, top=.9)\n",
    "plt.suptitle('Grid Cell Area ($m^2$) Tiles 1 and 2', fontsize=18);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading all 13 tiles of a state estimate field with ``load_ecco_var_from_tiles_nc``\n",
    "\n",
    "The routine ``load_ecco_var_from_tiles_nc`` loads all 13 tiles of a model output variable of name **var_name** from a single directory:\n",
    "\n",
    "Let's demonstrate with ``THETA``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:    (i: 90, j: 90, k: 50, nv: 2, tile: 13)\n",
       "Coordinates:\n",
       "  * j          (j) int32 0 1 2 3 4 5 6 7 8 9 ... 80 81 82 83 84 85 86 87 88 89\n",
       "  * i          (i) int32 0 1 2 3 4 5 6 7 8 9 ... 80 81 82 83 84 85 86 87 88 89\n",
       "  * k          (k) int32 0 1 2 3 4 5 6 7 8 9 ... 40 41 42 43 44 45 46 47 48 49\n",
       "    Z          (k) float32 -5.0 -15.0 -25.0 -35.0 ... -5039.25 -5461.25 -5906.25\n",
       "    PHrefC     (k) float32 49.05 147.15 245.25 ... 49435.043 53574.863 57940.312\n",
       "    drF        (k) float32 10.0 10.0 10.0 10.0 10.0 ... 387.5 410.5 433.5 456.5\n",
       "    time_bnds  (nv) datetime64[ns] 2010-03-01 2010-04-01\n",
       "    iter       int32 159948\n",
       "    time       datetime64[ns] 2010-03-16T12:00:00\n",
       "    XC         (tile, j, i) float32 -111.60647 -111.303 ... -111.86579\n",
       "    YC         (tile, j, i) float32 -88.24259 -88.382515 ... -88.07871 -88.10267\n",
       "    rA         (tile, j, i) float32 362256450.0 363300960.0 ... 361119100.0\n",
       "    hFacC      (tile, k, j, i) float32 0.0 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0\n",
       "  * tile       (tile) int32 0 1 2 3 4 5 6 7 8 9 10 11 12\n",
       "Dimensions without coordinates: nv\n",
       "Data variables:\n",
       "    THETA      (tile, k, j, i) float32 0.0 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load one tile of the llc90 grid\n",
    "data_dir= ECCO_tiles_dir + '/mon_mean/THETA/2010/03/'\n",
    "\n",
    "theta_dataset = ecco.load_ecco_var_from_tiles_nc(data_dir, 'THETA').load()\n",
    "theta_dataset.attrs =[]\n",
    "theta_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with our grid field, we see ``THETA`` now has $tile$ as a new dimension.  The array of ``THETA`` is now $(tile, k, j, i)$.   Quickly, let's plot ``THETA`` for two different tiles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(10, 10))\n",
    "\n",
    "#  tile 2 T \n",
    "plt.subplot(221)\n",
    "T_ma = theta_dataset.THETA.where(grid_all_tiles.hFacC != 0, np.nan)\n",
    "T_ma.sel(tile=10, k=0).plot(cmap='jet', vmin=-2, vmax=30)\n",
    "\n",
    "#  tile 2 T\n",
    "plt.subplot(222)\n",
    "T_ma = theta_dataset.THETA.where(grid_all_tiles.hFacC != 0, np.nan)\n",
    "T_ma.sel(tile=11, k=0).plot(cmap='jet', vmin=-2, vmax=32)\n",
    "\n",
    "plt.subplots_adjust(bottom=0, right=1.2, top=.9)\n",
    "plt.suptitle('Potential temperature at model surface for tiles 2 and 11', fontsize=18);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why are tiles 2 and 11 'rotated'?\n",
    "\n",
    "We selected tiles 2 and 11 intentionally to remind you that in the llc90 grid, tiles 7-12 are rotated by 90 degrees relative to tiles 0-5. For tiles 7-12, the ``x-axis`` is oriented approximately north-south while the ``y-axis`` is oriented approximately east-west.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading a subset of tiles or vertical levels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both ``load_ecco_var_from_tiles_nc`` and ``load_ecco_grid_from_tiles_nc`` allow the user to specify particular tiles and/or depth levels using optional arguments with the \n",
    "*tiles_to_load* and *k_subset* optional arguments.  \n",
    "\n",
    "By default \n",
    "\n",
    "* *tiles_to_load* = range(13)     // range(13) = [0, 1, ... 12]\n",
    "* k_subset = []                   // empty list \n",
    "\n",
    "\n",
    "To load a subset of tiles, specify the desired tile indices in *tiles_to_load*.  For example, to load tiles 3,4 and 5:\n",
    "~~~~\n",
    "tiles_to_load = [3, 4, 5]\n",
    "~~~~\n",
    "\n",
    "Similarly, to load a subset of depth levels, specify the desired depth level indices in *k_subset*.  For example, to load the top 5 levels:\n",
    "~~~~\n",
    "tiles_to_load = [0,1,2,3,4]\n",
    "~~~~\n",
    "\n",
    "The following call loads ``THETA`` for tiles 0-5 and depth levels 0-10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.DataArray 'THETA' (tile: 6, k: 11, j: 90, i: 90)>\n",
       "array([[[[0.000000e+00, ..., 0.000000e+00],\n",
       "         ...,\n",
       "         [2.607735e+00, ..., 1.944377e+00]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.000000e+00, ..., 0.000000e+00],\n",
       "         ...,\n",
       "         [1.108904e+00, ..., 1.277304e-02]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[2.785707e+01, ..., 2.806310e+01],\n",
       "         ...,\n",
       "         [0.000000e+00, ..., 0.000000e+00]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[2.190366e+01, ..., 2.595283e+01],\n",
       "         ...,\n",
       "         [0.000000e+00, ..., 0.000000e+00]]]], dtype=float32)\n",
       "Coordinates:\n",
       "  * j        (j) int32 0 1 2 3 4 5 6 7 8 9 10 ... 80 81 82 83 84 85 86 87 88 89\n",
       "  * i        (i) int32 0 1 2 3 4 5 6 7 8 9 10 ... 80 81 82 83 84 85 86 87 88 89\n",
       "  * k        (k) int32 0 1 2 3 4 5 6 7 8 9 10\n",
       "    Z        (k) float32 -5.0 -15.0 -25.0 -35.0 ... -85.025 -95.095 -105.31\n",
       "    PHrefC   (k) float32 49.05 147.15 245.25 ... 834.0953 932.88196 1033.0911\n",
       "    drF      (k) float32 10.0 10.0 10.0 10.0 10.0 ... 10.01 10.03 10.11 10.32\n",
       "    iter     int32 159948\n",
       "    time     datetime64[ns] 2010-03-16T12:00:00\n",
       "    XC       (tile, j, i) float32 -111.60647 -111.303 ... 141.44421 141.83792\n",
       "    YC       (tile, j, i) float32 -88.24259 -88.382515 ... 67.53387 67.47211\n",
       "    rA       (tile, j, i) float32 362256450.0 363300960.0 ... 212633870.0\n",
       "    hFacC    (tile, k, j, i) float32 0.0 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0 0.0\n",
       "  * tile     (tile) int32 0 1 2 3 4 5\n",
       "Attributes:\n",
       "    units:          degC\n",
       "    long_name:      Potential Temperature\n",
       "    standard_name:  sea_water_potential_temperature"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_dataset = ecco.load_ecco_var_from_tiles_nc(data_dir, 'THETA', \\\n",
    "                                                 tiles_to_load = [0,1,2,3,4,5], \\\n",
    "                                                 k_subset=[0,1,2,3,4,5,6,7,8,9,10]).load()\n",
    "theta_dataset.attrs = []\n",
    "theta_dataset.THETA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the $k$ dimension is length 11 and the $tile$ dimension is length 6.  The ``tile`` dimension coordinate has values [0,1,2,3,4,5] as requested."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading several state estimate fields with ``recursive_load_ecco_var_from_tiles_nc``\n",
    "\n",
    "With ``recursive_load_ecco_var_from_tiles_nc`` you can load multiple time levels from a single variable or many variables.  Specify:\n",
    "\n",
    "1. a top level directory, \n",
    "2. a list of variables to load\n",
    "3. a list of tiles to load\n",
    "4. a list of years to load\n",
    "5. a list of vertical level to load\n",
    "\n",
    "and this routine will search through all subdirectories and load all appropriate $tile$ files.\n",
    "\n",
    "\n",
    "#### Loading several years of **one** state estimate field\n",
    "\n",
    "Let's use this recursive load routine to load all monthly-mean ``SSH`` and ``THETA`` fields from tiles 0-2 for the year 2010 and depth level 10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "searching 01 for variables \n",
      "searching 02 for variables \n",
      "searching 03 for variables \n",
      "searching 04 for variables \n",
      "searching 05 for variables \n",
      "searching 06 for variables \n",
      "searching 07 for variables \n",
      "searching 08 for variables \n",
      "searching 09 for variables \n",
      "searching 10 for variables \n",
      "searching 11 for variables \n",
      "searching 12 for variables \n",
      "located directories with SSH \n"
     ]
    }
   ],
   "source": [
    "# Load one tile of the llc90 grid\n",
    "ssh_dir= ECCO_tiles_dir + '/mon_mean/SSH/2010/'\n",
    "\n",
    "SSH_2010 = \\\n",
    "    ecco.recursive_load_ecco_var_from_tiles_nc(ssh_dir, \\\n",
    "                                                  'SSH', \\\n",
    "                                                  tiles_to_load = [0,1,2],\n",
    "                                                  years_to_load = 2010,\n",
    "                                                  k_subset = 10).load()\n",
    "SSH_2010.attrs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:    (i: 90, j: 90, nv: 2, tile: 3, time: 12)\n",
       "Coordinates:\n",
       "  * j          (j) int32 0 1 2 3 4 5 6 7 8 9 ... 80 81 82 83 84 85 86 87 88 89\n",
       "  * i          (i) int32 0 1 2 3 4 5 6 7 8 9 ... 80 81 82 83 84 85 86 87 88 89\n",
       "    XC         (tile, j, i) float32 -111.60647 -111.303 ... 51.44421 51.837925\n",
       "    YC         (tile, j, i) float32 -88.24259 -88.382515 ... 67.53387 67.47211\n",
       "    rA         (tile, j, i) float32 362256450.0 363300960.0 ... 212633870.0\n",
       "  * tile       (tile) int32 0 1 2\n",
       "    time_bnds  (time, nv) datetime64[ns] 2010-01-01 2010-02-01 ... 2011-01-01\n",
       "    iter       (time) int32 158532 159204 159948 160668 ... 165084 165804 166548\n",
       "  * time       (time) datetime64[ns] 2010-01-16T12:00:00 ... 2010-12-16T12:00:00\n",
       "Dimensions without coordinates: nv\n",
       "Data variables:\n",
       "    SSH        (time, tile, j, i) float32 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SSH_2010"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting field has 3 tiles [0,1,2] and 12 time levels one for each month of 2010!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.DataArray 'time' (time: 12)>\n",
       "array(['2010-01-16T12:00:00.000000000', '2010-02-15T00:00:00.000000000',\n",
       "       '2010-03-16T12:00:00.000000000', '2010-04-16T00:00:00.000000000',\n",
       "       '2010-05-16T12:00:00.000000000', '2010-06-16T00:00:00.000000000',\n",
       "       '2010-07-16T12:00:00.000000000', '2010-08-16T12:00:00.000000000',\n",
       "       '2010-09-16T00:00:00.000000000', '2010-10-16T12:00:00.000000000',\n",
       "       '2010-11-16T00:00:00.000000000', '2010-12-16T12:00:00.000000000'],\n",
       "      dtype='datetime64[ns]')\n",
       "Coordinates:\n",
       "    iter     (time) int32 158532 159204 159948 160668 ... 165084 165804 166548\n",
       "  * time     (time) datetime64[ns] 2010-01-16T12:00:00 ... 2010-12-16T12:00:00\n",
       "Attributes:\n",
       "    long_name:      center time of averaging period\n",
       "    standard_name:  time\n",
       "    bounds:         time_bnds\n",
       "    axis:           T"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SSH_2010.time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading several years of **multiple** state estimate fields\n",
    "\n",
    "Now let's use the recursive load tile routine to load all monthly-mean ``SSH``, ``THETA``, and ``SALT`` fields from tile 6.  Use the directory that contains the variables as the the top-level directory.  The routine will recursively search all subdirectories for these fields.\n",
    "\n",
    "> Note :: This operation may take a minute because it is loading 365x3 2D fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "searching OBP for variables \n",
      "searching PHIBOT for variables \n",
      "searching SIarea for variables \n",
      "searching SSH for variables \n",
      "located directories with SSH \n",
      "no subdirectories with THETA \n",
      "no subdirectories with SALT \n"
     ]
    }
   ],
   "source": [
    "var_dir= ECCO_tiles_dir + '/day_mean/'\n",
    "\n",
    "SSH_THETA_SALT = \\\n",
    "    ecco.recursive_load_ecco_var_from_tiles_nc(var_dir, \\\n",
    "                                               ['SSH', 'THETA','SALT'], \\\n",
    "                                               tiles_to_load = [6], \\\n",
    "                                               years_to_load=2010, \\\n",
    "                                               less_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:    (i: 90, j: 90, nv: 2, time: 365)\n",
       "Coordinates:\n",
       "    XC         (j, i) float32 52.0 52.331654 52.769016 ... -127.66834 -128.0\n",
       "    YC         (j, i) float32 67.57341 67.67698 67.79265 ... 67.67698 67.57341\n",
       "    rA         (j, i) float32 246414940.0 412417600.0 ... 246414940.0\n",
       "  * j          (j) int32 0 1 2 3 4 5 6 7 8 9 ... 80 81 82 83 84 85 86 87 88 89\n",
       "  * i          (i) int32 0 1 2 3 4 5 6 7 8 9 ... 80 81 82 83 84 85 86 87 88 89\n",
       "    tile       int32 6\n",
       "    time_bnds  (time, nv) datetime64[ns] dask.array<shape=(365, 2), chunksize=(2, 2)>\n",
       "    iter       (time) int32 157812 157836 157860 157884 ... 166500 166524 166548\n",
       "  * time       (time) datetime64[ns] 2010-01-01T12:00:00 ... 2010-12-31T12:00:00\n",
       "Dimensions without coordinates: nv\n",
       "Data variables:\n",
       "    SSH        (time, j, i) float32 dask.array<shape=(365, 90, 90), chunksize=(1, 90, 90)>\n",
       "Attributes:\n",
       "    product_time_coverage_start:  1992-01-01T12:00:00\n",
       "    author:                       Ian Fenty and Ou Wang\n",
       "    Insitution:                   JPL\n",
       "    product_version:              ECCO Version 4 Release 3 (ECCOv4r3) 1992-2015\n",
       "    time_units:                   days since 1992-01-01 00:00:00\n",
       "    Conventions:                  CF-1.6\n",
       "    Project:                      Estimating the Circulation and Climate of t...\n",
       "    cdm_data_type:                Grid\n",
       "    geospatial_lon_units:         degrees_east\n",
       "    Metadata_Conventions:         CF-1.6, Unidata Dataset Discovery v1.0, GDS...\n",
       "    no_data:                      NaNf\n",
       "    geospatial_lat_units:         degrees_north\n",
       "    product_time_coverage_end:    2015-12-31T12:00:00\n",
       "    geospatial_vertical_min:      0\n",
       "    nz:                           1\n",
       "    geospatial_vertical_units:    meter\n",
       "    geospatial_vertical_max:      0\n",
       "    date_created:                 Tue May 14 15:42:08 2019\n",
       "    geospatial_lat_max:           89.739395\n",
       "    geospatial_lat_min:           67.57341\n",
       "    nx:                           90\n",
       "    ny:                           90\n",
       "    geospatial_lon_max:           179.9739\n",
       "    geospatial_lon_min:           -179.98895\n",
       "    time_coverage_start:          2010-01-01T00:00:00\n",
       "    time_coverage_end:            2011-01-01T00:00:00"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SSH_THETA_SALT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting *SSH_THETA_SALT* ``DATASET`` object has ``SALT``, ``THETA``, and ``SSH`` as data variables.  That's pretty cool.\n",
    "\n",
    "\n",
    "## Loading ECCO NetCDF files aggregated by year (Format 2)\n",
    "\n",
    "Finally, we'll show how to load ECCO NetCDF files aggregated by year.  These routines mirror those used above and therefore this part of the tutorial is brief.\n",
    "\n",
    "### Loading model *grid* fields\n",
    "\n",
    "In Format 2, all 13 tiles are aggregated so the model **grid** is in one file. Load it using the ``open_dataset`` routine from ``xarray``. \n",
    "\n",
    "> Note :: Please notice that the top-level directory for ECCOv4 NetCDF files aggregated by year (Format 2) will be different than those separated by time and tile (Format 1)!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:  (i: 90, i_g: 90, j: 90, j_g: 90, k: 50, k_l: 50, k_p1: 51, k_u: 50, tile: 13)\n",
       "Coordinates:\n",
       "  * k_p1     (k_p1) int64 0 1 2 3 4 5 6 7 8 9 ... 41 42 43 44 45 46 47 48 49 50\n",
       "  * j_g      (j_g) int64 0 1 2 3 4 5 6 7 8 9 ... 80 81 82 83 84 85 86 87 88 89\n",
       "  * i_g      (i_g) int64 0 1 2 3 4 5 6 7 8 9 ... 80 81 82 83 84 85 86 87 88 89\n",
       "  * k        (k) int64 0 1 2 3 4 5 6 7 8 9 10 ... 40 41 42 43 44 45 46 47 48 49\n",
       "  * j        (j) int64 0 1 2 3 4 5 6 7 8 9 10 ... 80 81 82 83 84 85 86 87 88 89\n",
       "  * k_u      (k_u) int64 0 1 2 3 4 5 6 7 8 9 ... 40 41 42 43 44 45 46 47 48 49\n",
       "  * i        (i) int64 0 1 2 3 4 5 6 7 8 9 10 ... 80 81 82 83 84 85 86 87 88 89\n",
       "  * k_l      (k_l) int64 0 1 2 3 4 5 6 7 8 9 ... 40 41 42 43 44 45 46 47 48 49\n",
       "  * tile     (tile) int64 0 1 2 3 4 5 6 7 8 9 10 11 12\n",
       "    XC       (tile, j, i) float32 ...\n",
       "    YC       (tile, j, i) float32 ...\n",
       "    XG       (tile, j_g, i_g) float32 ...\n",
       "    YG       (tile, j_g, i_g) float32 ...\n",
       "    Zl       (k_l) float32 ...\n",
       "    Zu       (k_u) float32 ...\n",
       "    Z        (k) float32 ...\n",
       "    Zp1      (k_p1) float32 ...\n",
       "    dxC      (tile, j, i_g) float32 ...\n",
       "    rAs      (tile, j_g, i) float32 ...\n",
       "    rAw      (tile, j, i_g) float32 ...\n",
       "    Depth    (tile, j, i) float32 ...\n",
       "    rA       (tile, j, i) float32 ...\n",
       "    dxG      (tile, j_g, i) float32 ...\n",
       "    dyG      (tile, j, i_g) float32 ...\n",
       "    rAz      (tile, j_g, i_g) float32 ...\n",
       "    dyC      (tile, j_g, i) float32 ...\n",
       "    PHrefC   (k) float32 ...\n",
       "    drC      (k_p1) float32 ...\n",
       "    PHrefF   (k_p1) float32 ...\n",
       "    drF      (k) float32 ...\n",
       "    hFacS    (k, tile, j_g, i) float32 ...\n",
       "    hFacC    (k, tile, j, i) float32 ...\n",
       "    hFacW    (k, tile, j, i_g) float32 ...\n",
       "Data variables:\n",
       "    *empty*"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define a high-level directory for ECCO fields\n",
    "ECCO_dir = '/Users/ifenty/eccov4r3_native_grid_netcdf/'\n",
    "\n",
    "# Load one tile of the llc90 grid\n",
    "grid_dir= ECCO_dir + 'grid/'\n",
    "\n",
    "grid = xr.open_dataset(grid_dir + 'ECCOv4r3_grid.nc')\n",
    "grid.attrs = []\n",
    "grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "all 13 tiles are present in this single file.\n",
    "\n",
    "### Loading a single year of a state estimate field \n",
    "\n",
    "In Format 2, all 13 tiles are aggregated and all fields for a given year are aggregated so to load a single year of a state estimate field we can use the ``open_dataset`` routine from ``xarray``.  Let's open one year's worth of daily sea ice concentration fields from 2010."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.DataArray 'SIarea' (time: 365, tile: 13, j: 90, i: 90)>\n",
       "[38434500 values with dtype=float32]\n",
       "Coordinates:\n",
       "    iter     (time) int32 ...\n",
       "  * time     (time) datetime64[ns] 2010-01-01T12:00:00 ... 2010-12-31T12:00:00\n",
       "  * j        (j) int32 0 1 2 3 4 5 6 7 8 9 10 ... 80 81 82 83 84 85 86 87 88 89\n",
       "  * i        (i) int32 0 1 2 3 4 5 6 7 8 9 10 ... 80 81 82 83 84 85 86 87 88 89\n",
       "    XC       (tile, j, i) float32 ...\n",
       "    YC       (tile, j, i) float32 ...\n",
       "    rA       (tile, j, i) float32 ...\n",
       "  * tile     (tile) int32 0 1 2 3 4 5 6 7 8 9 10 11 12\n",
       "Attributes:\n",
       "    units:          1\n",
       "    long_name:      SEAICE fractional ice-covered area [0 to 1]\n",
       "    standard_name:  sea_ice_area_fraction"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "siarea_dir= ECCO_dir + 'day_mean/SIarea/'\n",
    "\n",
    "siarea_dataset = xr.open_dataset(siarea_dir + '/SIarea_2010.nc')\n",
    "siarea_dataset.attrs = []\n",
    "siarea_dataset.SIarea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``SIarea`` has 13 tiles, 365 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.QuadMesh at 0x10fc22910>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig=plt.figure(figsize=(10, 10))\n",
    "s_ma_jan0 = siarea_dataset.SIarea.isel(time=0)\n",
    "si_ma = s_ma_jan0.where(grid.hFacC.isel(k=0) != 0, np.nan)\n",
    "si_ma.isel(tile=6).plot(cmap='jet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading several years of a state estimate field using ``load_ecco_var_from_years_nc``\n",
    "\n",
    "Loading several years of a single tate estimate field is easy with  ``load_ecco_var_from_years_nc``.  You can specify *tile_to_load* and *k_subset* if you like, but that is purely optional:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:    (i: 90, j: 90, nv: 2, tile: 5, time: 365)\n",
       "Coordinates:\n",
       "    time_bnds  (time, nv) datetime64[ns] 2010-01-01 2010-01-02 ... 2011-01-01\n",
       "    iter       (time) int32 157812 157836 157860 157884 ... 166500 166524 166548\n",
       "  * time       (time) datetime64[ns] 2010-01-01T12:00:00 ... 2010-12-31T12:00:00\n",
       "  * j          (j) int32 0 1 2 3 4 5 6 7 8 9 ... 80 81 82 83 84 85 86 87 88 89\n",
       "  * i          (i) int32 0 1 2 3 4 5 6 7 8 9 ... 80 81 82 83 84 85 86 87 88 89\n",
       "    XC         (tile, j, i) float32 -37.5 -36.5 -35.5 ... -38.5 -38.5 -38.5\n",
       "    YC         (tile, j, i) float32 10.458642 10.458642 ... 11.438585 10.458642\n",
       "    rA         (tile, j, i) float32 11896091000.0 ... 11896091000.0\n",
       "  * tile       (tile) int32 2 5 6 7 10\n",
       "Dimensions without coordinates: nv\n",
       "Data variables:\n",
       "    SIarea     (time, tile, j, i) float32 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "si_area_subset = ecco.load_ecco_var_from_years_nc(siarea_dir, \\\n",
    "                                                  'SIarea', 2010, \\\n",
    "                                                  tiles_to_load = [2,5,6,7,10]).load()\n",
    "si_area_subset.attrs = []\n",
    "si_area_subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our ``SIarea`` field has 5 tiles for 2010.\n",
    "\n",
    "### Loading several years of a state estimate fields using ``recursive_load_ecco_var_from_years_nc``\n",
    "\n",
    "With ``recursive_load_ecco_var_from_years_nc`` one can specify one or more variables to load, one or more years to load, a subset of tiles and subset of vertical levels.  Let's demonstrate by loading up all daily-averaged ``SSH`` ```SSS``` and ``SST`` ad fields for the year 2010.\n",
    "\n",
    "> Note :: This operation is relatively fast because there are fewer coordinate variables to reload (3 as opposed to the 365 x 3 when we loaded these same fields split into tiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "searching /Users/ifenty/eccov4r3_native_grid_netcdf/day_mean/ for variables ... \n",
      "found  ['ETAN', 'OBP', 'PHIBOT', 'SALT', 'SIarea', 'SIheff', 'SIhsnow', 'SSH', 'THETA', 'sIceLoad'] \n",
      "\n",
      "finished searching for SALT ... success!\n",
      "finished searching for SSH ... success!\n",
      "finished searching for THETA ... success!\n"
     ]
    }
   ],
   "source": [
    "day_mean_dir= ECCO_dir + 'day_mean/'\n",
    "\n",
    "SSH_THETA_2010 = ecco.recursive_load_ecco_var_from_years_nc(day_mean_dir, \\\n",
    "                                           vars_to_load=['SSH','THETA', 'SALT'], \\\n",
    "                                           years_to_load='all').load()\n",
    "                                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:    (i: 90, j: 90, nv: 2, tile: 13, time: 365)\n",
       "Coordinates:\n",
       "    time_bnds  (time, nv) datetime64[ns] 2010-01-01 2010-01-02 ... 2011-01-01\n",
       "    iter       (time) int32 157812 157836 157860 157884 ... 166500 166524 166548\n",
       "  * time       (time) datetime64[ns] 2010-01-01T12:00:00 ... 2010-12-31T12:00:00\n",
       "  * j          (j) int32 0 1 2 3 4 5 6 7 8 9 ... 80 81 82 83 84 85 86 87 88 89\n",
       "  * i          (i) int32 0 1 2 3 4 5 6 7 8 9 ... 80 81 82 83 84 85 86 87 88 89\n",
       "    XC         (tile, j, i) float32 -111.60647 -111.303 ... -111.86579\n",
       "    YC         (tile, j, i) float32 -88.24259 -88.382515 ... -88.07871 -88.10267\n",
       "    rA         (tile, j, i) float32 362256450.0 363300960.0 ... 361119100.0\n",
       "  * tile       (tile) int32 0 1 2 3 4 5 6 7 8 9 10 11 12\n",
       "Dimensions without coordinates: nv\n",
       "Data variables:\n",
       "    THETA      (time, tile, j, i) float32 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0\n",
       "    SSH        (time, tile, j, i) float32 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0\n",
       "    SALT       (time, tile, j, i) float32 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0\n",
       "Attributes:\n",
       "    geospatial_lat_max:       89.739395\n",
       "    geospatial_lat_min:       -89.873055\n",
       "    nx:                       90\n",
       "    ny:                       90\n",
       "    geospatial_lon_max:       179.98691\n",
       "    geospatial_lon_min:       -179.98895\n",
       "    geospatial_vertical_max:  0\n",
       "    geospatial_vertical_min:  0\n",
       "    nz:                       1\n",
       "    time_coverage_start:      2010-01-01T00:00:00\n",
       "    time_coverage_end:        2011-01-01T00:00:00"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SSH_THETA_2010"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Loading\" the entire ECCOv4 dataset using Dask\n",
    "\n",
    "\n",
    "``ecco_v4_py`` leverages the amazing ``Dask`` capabilities via the ``xarray`` package.  What are these capabilities?  For our purposes, there are two, quoting from the ``Dask`` website, \n",
    "https://docs.dask.org/\n",
    "\n",
    "1. **Larger-than-memory:** Lets you work on datasets that are larger than your available memory by breaking up your array into many small pieces, operating on those pieces in an order that minimizes the memory footprint of your computation, and effectively streaming data from disk.*\n",
    "\n",
    "2. **Blocked Algorithms:** Perform large computations by performing many smaller computations\n",
    "\n",
    "In cluster environments ``Dask`` can distribute computations across many cores to speed up large redundant calculation.  A full description of ``Dask`` is far, far outside the scope of this tutorial.  For the moment, let us compare the operation of loading **all** the 2D daily-mean fields for 2010 both using ``Dask`` and without using ``Dask``.  Without ``Dask`` these fields will be loaded into memory.  With ``Dask`` we will only load a minimum of the ``Datasets``, the Dimensions and Coordinates.\n",
    "\n",
    "To demonstate some of the advantages of using ``DASK`` to load and analyze ECCO fields, let's load a large subset of monthly mean fields with and without ``Dask``.  Then we'll load all of the monthly-mean fields for one year.  At the end we'll compare their *times to load* and *memory footprints*.\n",
    "\n",
    "### Example 1: No Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "searching /Users/ifenty/eccov4r3_native_grid_netcdf/mon_mean/ for variables ... \n",
      "found  ['ADVr_SLT', 'ADVr_TH', 'ADVxHEFF', 'ADVxSNOW', 'ADVx_SLT', 'ADVx_TH', 'ADVyHEFF', 'ADVySNOW', 'ADVy_SLT', 'ADVy_TH', 'DFrE_SLT', 'DFrE_TH', 'DFrI_SLT', 'DFrI_TH', 'DFxEHEFF', 'DFxESNOW', 'DFxE_SLT', 'DFxE_TH', 'DFyEHEFF', 'DFyESNOW', 'DFyE_SLT', 'DFyE_TH', 'DRHODR', 'ETAN', 'EXFaqh', 'EXFatemp', 'EXFempmr', 'EXFevap', 'EXFhl', 'EXFhs', 'EXFlwdn', 'EXFlwnet', 'EXFpreci', 'EXFqnet', 'EXFroff', 'EXFswdn', 'EXFswnet', 'EXFtaux', 'EXFtauy', 'EXFuwind', 'EXFvwind', 'EXFwspee', 'GM_PsiX', 'GM_PsiY', 'MXLDEPTH', 'OBP', 'PHIBOT', 'PHIHYD', 'PHIHYDcR', 'RHOAnoma', 'SALT', 'SFLUX', 'SIarea', 'SIatmFW', 'SIatmQnt', 'SIheff', 'SIhsnow', 'SIsnPrcp', 'SIuice', 'SIvice', 'SSH', 'TFLUX', 'THETA', 'UVEL', 'UVELMASS', 'Um_dPHdx', 'VVEL', 'VVELMASS', 'Vm_dPHdy', 'WVELMASS', 'oceFWflx', 'oceQnet', 'oceQsw', 'oceSPDep', 'oceSPflx', 'oceSPtnd', 'oceTAUX', 'oceTAUY', 'sIceLoad'] \n",
      "\n",
      "finished searching for ADVr_SLT ... success!\n",
      "finished searching for ADVr_TH ... success!\n",
      "finished searching for ADVxHEFF ... success!\n",
      "finished searching for ADVxSNOW ... success!\n",
      "finished searching for ADVx_SLT ... success!\n",
      "finished searching for ADVx_TH ... success!\n",
      "finished searching for ADVyHEFF ... success!\n",
      "finished searching for ADVySNOW ... success!\n",
      "finished searching for ADVy_SLT ... success!\n",
      "finished searching for ADVy_TH ... success!\n",
      "finished searching for DFrE_SLT ... success!\n",
      "finished searching for DFrE_TH ... success!\n",
      "finished searching for DFrI_SLT ... success!\n",
      "finished searching for DFrI_TH ... success!\n",
      "finished searching for DFxEHEFF ... success!\n",
      "finished searching for DFxESNOW ... success!\n",
      "finished searching for DFxE_SLT ... success!\n",
      "finished searching for DFxE_TH ... success!\n",
      "finished searching for DFyEHEFF ... success!\n",
      "finished searching for DFyESNOW ... success!\n",
      "finished searching for DFyE_SLT ... success!\n",
      "finished searching for DFyE_TH ... success!\n",
      "finished searching for DRHODR ... success!\n",
      "finished searching for ETAN ... success!\n",
      "finished searching for EXFaqh ... success!\n",
      "finished searching for EXFatemp ... success!\n",
      "finished searching for EXFempmr ... success!\n",
      "finished searching for EXFevap ... success!\n",
      "finished searching for EXFhl ... success!\n",
      "finished searching for EXFhs ... success!\n",
      "finished searching for EXFlwdn ... success!\n",
      "finished searching for EXFlwnet ... success!\n",
      "finished searching for EXFpreci ... success!\n",
      "finished searching for EXFqnet ... success!\n",
      "finished searching for EXFroff ... success!\n"
     ]
    }
   ],
   "source": [
    "mon_mean_dir= ECCO_dir + 'mon_mean/'\n",
    "\n",
    "import time\n",
    "t_0 = time.time()\n",
    "vars_to_load = ['ADVr_SLT', 'ADVr_TH', 'ADVxHEFF', 'ADVxSNOW', \\\n",
    "                'ADVx_SLT', 'ADVx_TH', 'ADVyHEFF', 'ADVySNOW', \\\n",
    "                'ADVy_SLT', 'ADVy_TH', 'DFrE_SLT', 'DFrE_TH', \\\n",
    "                'DFrI_SLT', 'DFrI_TH', 'DFxEHEFF', 'DFxESNOW', \\\n",
    "                'DFxE_SLT', 'DFxE_TH', 'DFyEHEFF', 'DFyESNOW', \\\n",
    "                'DFyE_SLT', 'DFyE_TH', 'DRHODR', 'ETAN', 'EXFaqh',\\\n",
    "                'EXFatemp', 'EXFempmr', 'EXFevap', 'EXFhl', 'EXFhs', \\\n",
    "                'EXFlwdn', 'EXFlwnet', 'EXFpreci', 'EXFqnet', 'EXFroff']\n",
    "\n",
    "large_subset_no_dask = ecco.recursive_load_ecco_var_from_years_nc(mon_mean_dir, \\\n",
    "                                           vars_to_load=vars_to_load, \\\n",
    "                                           years_to_load=2010).load()\n",
    "delta_t_no_dask =  time.time() - t_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "loaded  large_subset_no_dask in 19 seconds \n"
     ]
    }
   ],
   "source": [
    "print ('\\nloaded  large_subset_no_dask in %d seconds ' % delta_t_no_dask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "searching /Users/ifenty/eccov4r3_native_grid_netcdf/mon_mean/ for variables ... \n",
      "found  ['ADVr_SLT', 'ADVr_TH', 'ADVxHEFF', 'ADVxSNOW', 'ADVx_SLT', 'ADVx_TH', 'ADVyHEFF', 'ADVySNOW', 'ADVy_SLT', 'ADVy_TH', 'DFrE_SLT', 'DFrE_TH', 'DFrI_SLT', 'DFrI_TH', 'DFxEHEFF', 'DFxESNOW', 'DFxE_SLT', 'DFxE_TH', 'DFyEHEFF', 'DFyESNOW', 'DFyE_SLT', 'DFyE_TH', 'DRHODR', 'ETAN', 'EXFaqh', 'EXFatemp', 'EXFempmr', 'EXFevap', 'EXFhl', 'EXFhs', 'EXFlwdn', 'EXFlwnet', 'EXFpreci', 'EXFqnet', 'EXFroff', 'EXFswdn', 'EXFswnet', 'EXFtaux', 'EXFtauy', 'EXFuwind', 'EXFvwind', 'EXFwspee', 'GM_PsiX', 'GM_PsiY', 'MXLDEPTH', 'OBP', 'PHIBOT', 'PHIHYD', 'PHIHYDcR', 'RHOAnoma', 'SALT', 'SFLUX', 'SIarea', 'SIatmFW', 'SIatmQnt', 'SIheff', 'SIhsnow', 'SIsnPrcp', 'SIuice', 'SIvice', 'SSH', 'TFLUX', 'THETA', 'UVEL', 'UVELMASS', 'Um_dPHdx', 'VVEL', 'VVELMASS', 'Vm_dPHdy', 'WVELMASS', 'oceFWflx', 'oceQnet', 'oceQsw', 'oceSPDep', 'oceSPflx', 'oceSPtnd', 'oceTAUX', 'oceTAUY', 'sIceLoad'] \n",
      "\n",
      "finished searching for ADVr_SLT ... success!\n",
      "finished searching for ADVr_TH ... success!\n",
      "finished searching for ADVxHEFF ... success!\n",
      "finished searching for ADVxSNOW ... success!\n",
      "finished searching for ADVx_SLT ... success!\n",
      "finished searching for ADVx_TH ... success!\n",
      "finished searching for ADVyHEFF ... success!\n",
      "finished searching for ADVySNOW ... success!\n",
      "finished searching for ADVy_SLT ... success!\n",
      "finished searching for ADVy_TH ... success!\n",
      "finished searching for DFrE_SLT ... success!\n",
      "finished searching for DFrE_TH ... success!\n",
      "finished searching for DFrI_SLT ... success!\n",
      "finished searching for DFrI_TH ... success!\n",
      "finished searching for DFxEHEFF ... success!\n",
      "finished searching for DFxESNOW ... success!\n",
      "finished searching for DFxE_SLT ... success!\n",
      "finished searching for DFxE_TH ... success!\n",
      "finished searching for DFyEHEFF ... success!\n",
      "finished searching for DFyESNOW ... success!\n",
      "finished searching for DFyE_SLT ... success!\n",
      "finished searching for DFyE_TH ... success!\n",
      "finished searching for DRHODR ... success!\n",
      "finished searching for ETAN ... success!\n",
      "finished searching for EXFaqh ... success!\n",
      "finished searching for EXFatemp ... success!\n",
      "finished searching for EXFempmr ... success!\n",
      "finished searching for EXFevap ... success!\n",
      "finished searching for EXFhl ... success!\n",
      "finished searching for EXFhs ... success!\n",
      "finished searching for EXFlwdn ... success!\n",
      "finished searching for EXFlwnet ... success!\n",
      "finished searching for EXFpreci ... success!\n",
      "finished searching for EXFqnet ... success!\n",
      "finished searching for EXFroff ... success!\n"
     ]
    }
   ],
   "source": [
    "t_0 = time.time()\n",
    "large_subset_with_dask = ecco.recursive_load_ecco_var_from_years_nc(mon_mean_dir, \\\n",
    "                                           vars_to_load=vars_to_load, \\\n",
    "                                           years_to_load=2010)\n",
    "delta_t_with_dask =  time.time() - t_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "loaded  large_subset_with_dask in 10 seconds \n"
     ]
    }
   ],
   "source": [
    "print ('\\nloaded  large_subset_with_dask in %d seconds ' % delta_t_with_dask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "searching /Users/ifenty/eccov4r3_native_grid_netcdf/mon_mean/ for variables ... \n",
      "found  ['ADVr_SLT', 'ADVr_TH', 'ADVxHEFF', 'ADVxSNOW', 'ADVx_SLT', 'ADVx_TH', 'ADVyHEFF', 'ADVySNOW', 'ADVy_SLT', 'ADVy_TH', 'DFrE_SLT', 'DFrE_TH', 'DFrI_SLT', 'DFrI_TH', 'DFxEHEFF', 'DFxESNOW', 'DFxE_SLT', 'DFxE_TH', 'DFyEHEFF', 'DFyESNOW', 'DFyE_SLT', 'DFyE_TH', 'DRHODR', 'ETAN', 'EXFaqh', 'EXFatemp', 'EXFempmr', 'EXFevap', 'EXFhl', 'EXFhs', 'EXFlwdn', 'EXFlwnet', 'EXFpreci', 'EXFqnet', 'EXFroff', 'EXFswdn', 'EXFswnet', 'EXFtaux', 'EXFtauy', 'EXFuwind', 'EXFvwind', 'EXFwspee', 'GM_PsiX', 'GM_PsiY', 'MXLDEPTH', 'OBP', 'PHIBOT', 'PHIHYD', 'PHIHYDcR', 'RHOAnoma', 'SALT', 'SFLUX', 'SIarea', 'SIatmFW', 'SIatmQnt', 'SIheff', 'SIhsnow', 'SIsnPrcp', 'SIuice', 'SIvice', 'SSH', 'TFLUX', 'THETA', 'UVEL', 'UVELMASS', 'Um_dPHdx', 'VVEL', 'VVELMASS', 'Vm_dPHdy', 'WVELMASS', 'oceFWflx', 'oceQnet', 'oceQsw', 'oceSPDep', 'oceSPflx', 'oceSPtnd', 'oceTAUX', 'oceTAUY', 'sIceLoad'] \n",
      "\n",
      "finished searching for ADVr_SLT ... success!\n",
      "finished searching for ADVr_TH ... success!\n",
      "finished searching for ADVxHEFF ... success!\n",
      "finished searching for ADVxSNOW ... success!\n",
      "finished searching for ADVx_SLT ... success!\n",
      "finished searching for ADVx_TH ... success!\n",
      "finished searching for ADVyHEFF ... success!\n",
      "finished searching for ADVySNOW ... success!\n",
      "finished searching for ADVy_SLT ... success!\n",
      "finished searching for ADVy_TH ... success!\n",
      "finished searching for DFrE_SLT ... success!\n",
      "finished searching for DFrE_TH ... success!\n",
      "finished searching for DFrI_SLT ... success!\n",
      "finished searching for DFrI_TH ... success!\n",
      "finished searching for DFxEHEFF ... success!\n",
      "finished searching for DFxESNOW ... success!\n",
      "finished searching for DFxE_SLT ... success!\n",
      "finished searching for DFxE_TH ... success!\n",
      "finished searching for DFyEHEFF ... success!\n",
      "finished searching for DFyESNOW ... success!\n",
      "finished searching for DFyE_SLT ... success!\n",
      "finished searching for DFyE_TH ... success!\n",
      "finished searching for DRHODR ... success!\n",
      "finished searching for ETAN ... success!\n",
      "finished searching for EXFaqh ... success!\n",
      "finished searching for EXFatemp ... success!\n",
      "finished searching for EXFempmr ... success!\n",
      "finished searching for EXFevap ... success!\n",
      "finished searching for EXFhl ... success!\n",
      "finished searching for EXFhs ... success!\n",
      "finished searching for EXFlwdn ... success!\n",
      "finished searching for EXFlwnet ... success!\n",
      "finished searching for EXFpreci ... success!\n",
      "finished searching for EXFqnet ... success!\n",
      "finished searching for EXFroff ... success!\n",
      "finished searching for EXFswdn ... success!\n",
      "finished searching for EXFswnet ... success!\n",
      "finished searching for EXFtaux ... success!\n",
      "finished searching for EXFtauy ... success!\n",
      "finished searching for EXFuwind ... success!\n",
      "finished searching for EXFvwind ... success!\n",
      "finished searching for EXFwspee ... success!\n",
      "finished searching for GM_PsiX ... success!\n",
      "finished searching for GM_PsiY ... success!\n",
      "finished searching for MXLDEPTH ... success!\n",
      "finished searching for OBP ... success!\n",
      "finished searching for PHIBOT ... success!\n",
      "finished searching for PHIHYD ... success!\n",
      "finished searching for PHIHYDcR ... success!\n",
      "finished searching for RHOAnoma ... success!\n",
      "finished searching for SALT ... success!\n",
      "finished searching for SFLUX ... success!\n",
      "finished searching for SIarea ... success!\n",
      "finished searching for SIatmFW ... success!\n",
      "finished searching for SIatmQnt ... success!\n",
      "finished searching for SIheff ... success!\n",
      "finished searching for SIhsnow ... success!\n",
      "finished searching for SIsnPrcp ... success!\n",
      "finished searching for SIuice ... success!\n",
      "finished searching for SIvice ... success!\n",
      "finished searching for SSH ... success!\n",
      "finished searching for TFLUX ... success!\n",
      "finished searching for THETA ... success!\n",
      "finished searching for UVEL ... success!\n",
      "finished searching for UVELMASS ... success!\n",
      "finished searching for Um_dPHdx ... success!\n",
      "finished searching for VVEL ... success!\n",
      "finished searching for VVELMASS ... success!\n",
      "finished searching for Vm_dPHdy ... success!\n",
      "finished searching for WVELMASS ... success!\n",
      "finished searching for oceFWflx ... success!\n",
      "finished searching for oceQnet ... success!\n",
      "finished searching for oceQsw ... success!\n",
      "finished searching for oceSPDep ... success!\n",
      "finished searching for oceSPflx ... success!\n",
      "finished searching for oceSPtnd ... success!\n",
      "finished searching for oceTAUX ... success!\n",
      "finished searching for oceTAUY ... success!\n",
      "finished searching for sIceLoad ... success!\n"
     ]
    }
   ],
   "source": [
    "t_0 = time.time()\n",
    "all_fields_with_dask = ecco.recursive_load_ecco_var_from_years_nc(mon_mean_dir, \\\n",
    "                                           vars_to_load='all', \\\n",
    "                                           years_to_load=2010)\n",
    "delta_t_all_with_dask =  time.time() - t_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "loaded  all_with_dask in 41 seconds \n"
     ]
    }
   ],
   "source": [
    "print ('\\nloaded  all_with_dask in %d seconds ' % delta_t_all_with_dask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The real advantage comes when examining the size of these objects in memory.  Use the following routine from https://goshippo.com/blog/measure-real-size-any-python-object/ \n",
    "\n",
    "\n",
    "**execute the cell below to make the function available**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_size(obj, seen=None):\n",
    "    \"\"\"Recursively finds size of objects\"\"\"\n",
    "    size = sys.getsizeof(obj)\n",
    "    if seen is None:\n",
    "        seen = set()\n",
    "    obj_id = id(obj)\n",
    "    if obj_id in seen:\n",
    "        return 0\n",
    "    # Important mark as seen *before* entering recursion to gracefully handle\n",
    "    # self-referential objects\n",
    "    seen.add(obj_id)\n",
    "    if isinstance(obj, dict):\n",
    "        size += sum([get_size(v, seen) for v in obj.values()])\n",
    "        size += sum([get_size(k, seen) for k in obj.keys()])\n",
    "    elif hasattr(obj, '__dict__'):\n",
    "        size += get_size(obj.__dict__, seen)\n",
    "    elif hasattr(obj, '__iter__') and not isinstance(obj, (str, bytes, bytearray)):\n",
    "        size += sum([get_size(i, seen) for i in obj])\n",
    "    return size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46091179\n",
      "176299\n",
      "320027\n"
     ]
    }
   ],
   "source": [
    "print(get_size(large_subset_no_dask))\n",
    "print(get_size(large_subset_with_dask))\n",
    "print(get_size(all_fields_with_dask))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using ``Dask``, we were able to load every monthly mean field for an entire year in just over one minute.  That means one can use ``Dask`` to have all monthly-mean fields of the ECCOv4 state estimate avaiable to perform calculations on in about half an hour.\n",
    "\n",
    "In terms of memory, the *all_fields_with_dask* object takes less than 1% of the memory of *large_subset_no_dask*.  With much less memory reserved to hold all of the fields, we have more memory avaiable for calculations on the parts of the fields that we care about.\n",
    "\n",
    "Go ahead and experiment with using ``Dask`` to load the daily-averaged fields.  Because all of the daily-averaged fields in the standard ECCO product are 2D, loading them with ``Dask`` takes very little time!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Now you know how effecient ways to load ECCOv4 NetCDF files, both when you are reading variables split into *tiles*  and when you are reading variables aggregated by year.\n",
    "\n",
    "Using ``Dask`` we showed that one can prepare a work environment where ECCO model variables are accessible for calculations even without fully loading the fields into memory."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

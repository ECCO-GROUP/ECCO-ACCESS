{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving `Datasets` and `DataArrays` to NetCDF\n",
    "\n",
    "## Objectives\n",
    "\n",
    "Introduce an easy method for saving `Datasets` and `DataArrays` objects to NetCDF\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Saving your `Datasets` and `DataArrays` objects to NetCDF files couldn't be simpler.  The `xarray` module that we've been using to load NetCDF files provides methods for saving your `Datasets` and `DataArrays` as NetCDF files.\n",
    "\n",
    "Here is the manual page on the subjet: http://xarray.pydata.org/en/stable/generated/xarray.Dataset.to_netcdf.html\n",
    "\n",
    "The method `._to_netcdf( )` is available to **both** `Datasets` and `DataArrays` objects.  So useful!\n",
    "\n",
    "### Syntax\n",
    "``\n",
    "your_dataset.to_netcdf('/your_filepath/your_netcdf_filename.nc')\n",
    "``\n",
    "\n",
    "## Saving an existing `Dataset` to NetCDF\n",
    "\n",
    "First, let's set up the environment and load a `Dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## SET UP ENVIRONMENT\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import sys\n",
    "sys.path.append('/Users/ifenty/ECCOv4-py')\n",
    "import ecco_v4_py as ecco\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load a single tile, monthly averaged *THETA* for March 2010 for model tile 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## LOAD NETCDF FILE\n",
    "\n",
    "# define a high-level directory for ECCO fields\n",
    "ECCO_dir = '/Users/ifenty/eccov4r3_native_grid_netcdf_tiles/'\n",
    "# directory of the file\n",
    "data_dir= ECCO_dir + '/mon_mean/THETA/2010/03/'\n",
    "# filename\n",
    "fname = 'THETA_2010_03_tile_02.nc'\n",
    "# load the dataset file\n",
    "theta_dataset = xr.open_dataset(data_dir + fname).load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've loaded *theta_dataset*, let's save it in the **/tmp** file directory with a new name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving to  /tmp/test_output.nc\n",
      "finished saving\n"
     ]
    }
   ],
   "source": [
    "new_filename_1 = '/tmp/test_output.nc'\n",
    "print 'saving to ', new_filename_1\n",
    "theta_dataset.to_netcdf(path=new_filename_1)\n",
    "print 'finished saving'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*It's really that simple!*\n",
    "\n",
    "## Saving a new custom ``Dataset`` to NetCDF\n",
    "\n",
    "\n",
    "Now let's create a new custom `Dataset` that with *THETA*, *SSH* and model grid parameter variables for a few tiles and depth level 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "searching EXFqnet for variables \n",
      "searching SALT for variables \n",
      "searching SSH for variables \n",
      "searching THETA for variables \n",
      "searching UVEL for variables \n",
      "searching VVEL for variables \n",
      "located directories with SSH \n",
      "located directories with THETA \n"
     ]
    }
   ],
   "source": [
    "data_dir= ECCO_dir + '/mon_mean/'\n",
    "\n",
    "SSH_THETA_201003 = \\\n",
    "    ecco.recursive_load_ecco_var_from_tiles_nc(data_dir, \\\n",
    "                                              ['SSH', 'THETA'], \\\n",
    "                                              tiles_to_load = [0,1,2],\n",
    "                                              years_to_load = 2010)\n",
    "    \n",
    "grid = ecco.load_ecco_grid_from_tiles_nc(ECCO_dir + '/grid')    \n",
    "grid.close()\n",
    "\n",
    "custom_dataset = xr.merge([SSH_THETA_201003, grid])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and now we can easily save it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving to  /tmp/test_output_2.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/xarray/core/dataset.py:1232: SerializationWarning: saving variable time with floating point data as an integer dtype without any _FillValue to use for NaNs\n",
      "  compute=compute)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished saving\n"
     ]
    }
   ],
   "source": [
    "new_filename_2 = '/tmp/test_output_2.nc'\n",
    "print 'saving to ', new_filename_2\n",
    "custom_dataset.to_netcdf(path=new_filename_2)\n",
    "custom_dataset.close()\n",
    "print 'finished saving'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:    (i: 90, i_g: 90, j: 90, j_g: 90, k: 50, k_l: 50, k_p1: 51, k_u: 50, nv: 2, tile: 13, time: 12)\n",
       "Coordinates:\n",
       "  * tile       (tile) int64 0 1 2 3 4 5 6 7 8 9 10 11 12\n",
       "  * j          (j) int32 0 1 2 3 4 5 6 7 8 9 ... 80 81 82 83 84 85 86 87 88 89\n",
       "  * i          (i) int32 0 1 2 3 4 5 6 7 8 9 ... 80 81 82 83 84 85 86 87 88 89\n",
       "  * k          (k) int32 0 1 2 3 4 5 6 7 8 9 ... 40 41 42 43 44 45 46 47 48 49\n",
       "    Z          (k) float32 -5.0 -15.0 -25.0 -35.0 ... -5039.25 -5461.25 -5906.25\n",
       "    PHrefC     (k) float32 49.05 147.15 245.25 ... 49435.043 53574.863 57940.312\n",
       "    drF        (k) float32 10.0 10.0 10.0 10.0 10.0 ... 387.5 410.5 433.5 456.5\n",
       "    XC         (tile, j, i) float32 dask.array<shape=(13, 90, 90), chunksize=(2, 90, 90)>\n",
       "    YC         (tile, j, i) float32 dask.array<shape=(13, 90, 90), chunksize=(2, 90, 90)>\n",
       "    rA         (tile, j, i) float32 dask.array<shape=(13, 90, 90), chunksize=(2, 90, 90)>\n",
       "    hFacC      (tile, k, j, i) float32 dask.array<shape=(13, 50, 90, 90), chunksize=(2, 50, 90, 90)>\n",
       "    time_bnds  (time, nv) datetime64[ns] 2010-01-01 2010-02-01 ... 2011-01-01\n",
       "    iter       (time) int32 158532 159204 159948 160668 ... 165084 165804 166548\n",
       "  * time       (time) datetime64[ns] 2010-01-16T12:00:00 ... 2010-12-16T12:00:00\n",
       "  * k_p1       (k_p1) int64 0 1 2 3 4 5 6 7 8 9 ... 42 43 44 45 46 47 48 49 50\n",
       "  * j_g        (j_g) int64 0 1 2 3 4 5 6 7 8 9 ... 80 81 82 83 84 85 86 87 88 89\n",
       "  * i_g        (i_g) int64 0 1 2 3 4 5 6 7 8 9 ... 80 81 82 83 84 85 86 87 88 89\n",
       "  * k_u        (k_u) int64 0 1 2 3 4 5 6 7 8 9 ... 40 41 42 43 44 45 46 47 48 49\n",
       "  * k_l        (k_l) int64 0 1 2 3 4 5 6 7 8 9 ... 40 41 42 43 44 45 46 47 48 49\n",
       "    Zl         (k_l) float32 0.0 -10.0 -20.0 -30.0 ... -4834.0 -5244.5 -5678.0\n",
       "    Zu         (k_u) float32 -10.0 -20.0 -30.0 -40.0 ... -5244.5 -5678.0 -6134.5\n",
       "    Zp1        (k_p1) float32 0.0 -10.0 -20.0 -30.0 ... -5244.5 -5678.0 -6134.5\n",
       "    drC        (k_p1) float32 5.0 10.0 10.0 10.0 ... 399.0 422.0 445.0 228.25\n",
       "    PHrefF     (k_p1) float32 0.0 98.1 196.2 ... 51448.547 55701.18 60179.445\n",
       "    XG         (tile, j_g, i_g) float32 dask.array<shape=(13, 90, 90), chunksize=(2, 90, 90)>\n",
       "    YG         (tile, j_g, i_g) float32 dask.array<shape=(13, 90, 90), chunksize=(2, 90, 90)>\n",
       "    dxC        (tile, j, i_g) float32 dask.array<shape=(13, 90, 90), chunksize=(2, 90, 90)>\n",
       "    rAs        (tile, j_g, i) float32 dask.array<shape=(13, 90, 90), chunksize=(2, 90, 90)>\n",
       "    rAw        (tile, j, i_g) float32 dask.array<shape=(13, 90, 90), chunksize=(2, 90, 90)>\n",
       "    Depth      (tile, j, i) float32 dask.array<shape=(13, 90, 90), chunksize=(2, 90, 90)>\n",
       "    dxG        (tile, j_g, i) float32 dask.array<shape=(13, 90, 90), chunksize=(2, 90, 90)>\n",
       "    dyG        (tile, j, i_g) float32 dask.array<shape=(13, 90, 90), chunksize=(2, 90, 90)>\n",
       "    rAz        (tile, j_g, i_g) float32 dask.array<shape=(13, 90, 90), chunksize=(2, 90, 90)>\n",
       "    dyC        (tile, j_g, i) float32 dask.array<shape=(13, 90, 90), chunksize=(2, 90, 90)>\n",
       "    hFacS      (tile, k, j_g, i) float32 dask.array<shape=(13, 50, 90, 90), chunksize=(2, 50, 90, 90)>\n",
       "    hFacW      (tile, k, j, i_g) float32 dask.array<shape=(13, 50, 90, 90), chunksize=(2, 50, 90, 90)>\n",
       "Dimensions without coordinates: nv\n",
       "Data variables:\n",
       "    THETA      (time, tile, k, j, i) float32 dask.array<shape=(12, 13, 50, 90, 90), chunksize=(1, 1, 50, 90, 90)>\n",
       "    SSH        (time, tile, j, i) float32 dask.array<shape=(12, 13, 90, 90), chunksize=(1, 1, 90, 90)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verifying our new NetCDF files\n",
    "\n",
    "To verify that ``to_netcdf()`` worked, load them and compare with the originals.\n",
    "\n",
    "### Compare *theta_dataset* with *dataset_1*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the first test dataset\n",
    "dataset_1 = xr.open_dataset(new_filename_1)\n",
    "# release the file handle (not necessary but generally a good idea)\n",
    "dataset_1.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `np.allclose` method does element-by-element comparison of variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking THETA \n",
      "-- identical in dataset_1 and theta_dataset : True\n"
     ]
    }
   ],
   "source": [
    "# loop through the data variables in dataset_1\n",
    "for key in dataset_1.keys():\n",
    "    print ('checking %s ' % key)\n",
    "    print ('-- identical in dataset_1 and theta_dataset : %s' % \\\n",
    "           np.allclose(dataset_1[key], theta_dataset[key], equal_nan=True))\n",
    "    \n",
    "# note: ``equal_nan`` means nan==nan (default nan != nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*THETA* is the same in both datasets.\n",
    "\n",
    "### Compare *custom_dataset* with *dataset_2*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished loading\n"
     ]
    }
   ],
   "source": [
    "# our custom dataset\n",
    "dataset_2 = xr.open_dataset(new_filename_2)\n",
    "dataset_2.close()\n",
    "print 'finished loading'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking THETA \n",
      "-- identical in dataset_2 and custom_dataset : True\n",
      "checking SSH \n",
      "-- identical in dataset_2 and custom_dataset : True\n"
     ]
    }
   ],
   "source": [
    "for key in dataset_2.keys():\n",
    "    print ('checking %s ' % key)\n",
    "    print ('-- identical in dataset_2 and custom_dataset : %s'\\\n",
    "           % np.allclose(dataset_2[key], custom_dataset[key], equal_nan=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*THETA* and *SSH* are the same in both datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So nice to hear!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the results of calculations\n",
    "\n",
    "### Calculations in the form of `DataArrays`\n",
    "Often we would like to store the results of our calculations to disk.  If your operations are made at the level of `DataArray` objects (and not the lower `ndarray` level) then you can use these same methods to save your results.  All of the coordinates will be preserved (although attributes be lost).  Let's demonstrate by making a dummy calculation on SSH\n",
    "\n",
    "$$SSH_{sq}(i) = SSH(i)^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.DataArray 'SSH' (time: 12, tile: 13, j: 90, i: 90)>\n",
       "dask.array<shape=(12, 13, 90, 90), dtype=float32, chunksize=(1, 1, 90, 90)>\n",
       "Coordinates:\n",
       "  * tile     (tile) int64 0 1 2 3 4 5 6 7 8 9 10 11 12\n",
       "  * j        (j) int32 0 1 2 3 4 5 6 7 8 9 10 ... 80 81 82 83 84 85 86 87 88 89\n",
       "  * i        (i) int32 0 1 2 3 4 5 6 7 8 9 10 ... 80 81 82 83 84 85 86 87 88 89\n",
       "    XC       (tile, j, i) float32 dask.array<shape=(13, 90, 90), chunksize=(2, 90, 90)>\n",
       "    YC       (tile, j, i) float32 dask.array<shape=(13, 90, 90), chunksize=(2, 90, 90)>\n",
       "    rA       (tile, j, i) float32 dask.array<shape=(13, 90, 90), chunksize=(2, 90, 90)>\n",
       "    iter     (time) int32 158532 159204 159948 160668 ... 165084 165804 166548\n",
       "  * time     (time) datetime64[ns] 2010-01-16T12:00:00 ... 2010-12-16T12:00:00\n",
       "    Depth    (tile, j, i) float32 dask.array<shape=(13, 90, 90), chunksize=(2, 90, 90)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SSH_sq = custom_dataset.SSH * custom_dataset.SSH\n",
    "\n",
    "SSH_sq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*SSH_sq* is itself a `DataArray`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before saving, let's give our new *SSH_sq* variable a better name and descriptive attributes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.DataArray 'SSH^2' (time: 12, tile: 13, j: 90, i: 90)>\n",
       "dask.array<shape=(12, 13, 90, 90), dtype=float32, chunksize=(1, 1, 90, 90)>\n",
       "Coordinates:\n",
       "  * tile     (tile) int64 0 1 2 3 4 5 6 7 8 9 10 11 12\n",
       "  * j        (j) int32 0 1 2 3 4 5 6 7 8 9 10 ... 80 81 82 83 84 85 86 87 88 89\n",
       "  * i        (i) int32 0 1 2 3 4 5 6 7 8 9 10 ... 80 81 82 83 84 85 86 87 88 89\n",
       "    XC       (tile, j, i) float32 dask.array<shape=(13, 90, 90), chunksize=(2, 90, 90)>\n",
       "    YC       (tile, j, i) float32 dask.array<shape=(13, 90, 90), chunksize=(2, 90, 90)>\n",
       "    rA       (tile, j, i) float32 dask.array<shape=(13, 90, 90), chunksize=(2, 90, 90)>\n",
       "    iter     (time) int32 158532 159204 159948 160668 ... 165084 165804 166548\n",
       "  * time     (time) datetime64[ns] 2010-01-16T12:00:00 ... 2010-12-16T12:00:00\n",
       "    Depth    (tile, j, i) float32 dask.array<shape=(13, 90, 90), chunksize=(2, 90, 90)>\n",
       "Attributes:\n",
       "    long_name:  Square of Surface Height Anomaly\n",
       "    units:      m^2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SSH_sq.name = 'SSH^2'\n",
    "SSH_sq.attrs['long_name'] = 'Square of Surface Height Anomaly'\n",
    "SSH_sq.attrs['units'] = 'm^2'\n",
    "\n",
    "# Let's see the result\n",
    "SSH_sq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "much better!  Now we'll save."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving to  /tmp/ssh_sq_DataArray.nc\n",
      "finished saving\n"
     ]
    }
   ],
   "source": [
    "new_filename_3 = '/tmp/ssh_sq_DataArray.nc'\n",
    "print 'saving to ', new_filename_3\n",
    "\n",
    "SSH_sq.to_netcdf(path=new_filename_3)\n",
    "print 'finished saving'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Calculations in the form of `numpy ndarrays`\n",
    "\n",
    "If calculations are made at the `ndarray` level then the results will also be `ndarrays`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SSH_dummy_ndarray = custom_dataset.SSH.values *  custom_dataset.SSH.values\n",
    "\n",
    "type(SSH_dummy_ndarray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll need to use different methods to save these results to NetCDF files, one of which is described here: http://pyhogs.github.io/intro_netcdf4.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Saving `Datasets` and `DataArrays` to disk as NetCDF files is fun and easy with ``xarray``!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving `Datasets` and `DataArrays` to NetCDF\n",
    "\n",
    "## Objectives\n",
    "\n",
    "Introduce an easy method for saving `Datasets` and `DataArrays` objects to NetCDF\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Saving your `Datasets` and `DataArrays` objects to NetCDF couldn't be simpler.  The `xarray` module that we've been using to load NetCDF files from disk provides methods for direct writing to NetCDF.\n",
    "\n",
    "Here is the manual page on the subjet: http://xarray.pydata.org/en/stable/generated/xarray.Dataset.to_netcdf.html\n",
    "\n",
    "The method is called `._to_netcdf( )` and it available to both `Datasets` and `DataArrays` objects.\n",
    "\n",
    "### Syntax\n",
    "``\n",
    "your_dataset.to_netcdf('/your_filepath/your_netcdf_filename.nc')\n",
    "``\n",
    "\n",
    "## Saving a `Dataset`\n",
    "\n",
    "First, let's load a `Dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished loading all 13 tiles of GRID\n",
      "Finished loading all 13 tiles of SSH\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import ecco_v4_py as ecco\n",
    "\n",
    "ECCO_dir = '/Users/ifenty/ECCOv4/R3'\n",
    "\n",
    "# Load all tiles of the LLC90 Grid    \n",
    "data_dir= ECCO_dir + '/nctiles_grid/'    \n",
    "var = 'GRID'\n",
    "var_type = 'grid'\n",
    "\n",
    "grid_all_tiles = ecco.load_all_tiles_from_netcdf(data_dir, \n",
    "                                                 var, var_type,\n",
    "                                                 less_output=True)\n",
    "\n",
    "# Load all tiles of SSH\n",
    "data_dir= ECCO_dir + '/nctiles_monthly/SSH/'    \n",
    "var = 'SSH'\n",
    "var_type = 'c'\n",
    "ssh_all_tiles = ecco.load_all_tiles_from_netcdf(data_dir, \n",
    "                                                var, var_type,\n",
    "                                                less_output=True)\n",
    "\n",
    "# minimize the metadata (optional)\n",
    "data = xr.merge([ssh_all_tiles, grid_all_tiles])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving a `Dataset`\n",
    "\n",
    "Now that we've loaded *ssh_all_tiles*, let's save it in the *SSH* file directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving to  /Users/ifenty/ECCOv4/R3/nctiles_monthly/SSH/data_all_tiles.nc\n",
      "finished saving\n"
     ]
    }
   ],
   "source": [
    "new_filename = data_dir + 'data_all_tiles.nc'\n",
    "print 'saving to ', new_filename\n",
    "\n",
    "data.to_netcdf(path=new_filename)\n",
    "print 'finished saving'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create a new `Dataset` that only including *SSH* and some grid parameter variables that are on the same $c$ grid points as *SSH*.\n",
    "\n",
    "First, make three new `Datasets`, one for each variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:   (i: 90, j: 90, tile: 13, time: 288)\n",
       "Coordinates:\n",
       "  * time      (time) float64 1.0 2.0 3.0 4.0 5.0 6.0 7.0 8.0 9.0 10.0 11.0 ...\n",
       "  * j         (j) float64 1.0 2.0 3.0 4.0 5.0 6.0 7.0 8.0 9.0 10.0 11.0 12.0 ...\n",
       "  * i         (i) float64 1.0 2.0 3.0 4.0 5.0 6.0 7.0 8.0 9.0 10.0 11.0 12.0 ...\n",
       "    tim       (time) datetime64[ns] 1992-01-16 1992-02-16 1992-03-16 ...\n",
       "    timestep  (time) float64 732.0 1.428e+03 2.172e+03 2.892e+03 3.636e+03 ...\n",
       "    lon_c     (tile, j, i) float64 -111.6 -111.3 -110.9 -110.5 -110.0 -109.3 ...\n",
       "    lat_c     (tile, j, i) float64 -88.24 -88.38 -88.52 -88.66 -88.8 -88.94 ...\n",
       "  * tile      (tile) int64 1 2 3 4 5 6 7 8 9 10 11 12 13\n",
       "Data variables:\n",
       "    SSH       (time, tile, j, i) float64 nan nan nan nan nan nan nan nan nan ...\n",
       "    XC        (tile, j, i) float64 -111.6 -111.3 -110.9 -110.5 -110.0 -109.3 ...\n",
       "    YC        (tile, j, i) float64 -88.24 -88.38 -88.52 -88.66 -88.8 -88.94 ..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract these three DataArrays from the data object\n",
    "# and simultaneously convert them to one-variable Dataset objects\n",
    "SSH = data.SSH.to_dataset(name = 'SSH')\n",
    "XC  = data.XC.to_dataset(name = 'XC')\n",
    "YC  = data.YC.to_dataset(name = 'YC')\n",
    "\n",
    "# Merge these Datasets\n",
    "data_subset = xr.merge([SSH, XC , YC])\n",
    "\n",
    "# Give data_subset the same metadata attributes as data\n",
    "data_subset.attrs = data.attrs\n",
    "\n",
    "# Examine the results\n",
    "data_subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and now we can easily save it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving to  /Users/ifenty/ECCOv4/R3/nctiles_monthly/SSH/data_subset_all_tiles.nc\n",
      "finished saving\n"
     ]
    }
   ],
   "source": [
    "new_filename = data_dir + 'data_subset_all_tiles.nc'\n",
    "print 'saving to ', new_filename\n",
    "\n",
    "data_subset.to_netcdf(path=new_filename)\n",
    "print 'finished saving'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading our saved  `Dataset`\n",
    "\n",
    "To verify that our worked let's load it up and compare with *data_subset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished loading\n"
     ]
    }
   ],
   "source": [
    "new_filename = data_dir + 'data_subset_all_tiles.nc'\n",
    "\n",
    "data_subset_loaded = xr.open_dataset(new_filename)\n",
    "\n",
    "print 'finished loading'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:   (i: 90, j: 90, tile: 13, time: 288)\n",
       "Coordinates:\n",
       "  * time      (time) float64 1.0 2.0 3.0 4.0 5.0 6.0 7.0 8.0 9.0 10.0 11.0 ...\n",
       "  * j         (j) float64 1.0 2.0 3.0 4.0 5.0 6.0 7.0 8.0 9.0 10.0 11.0 12.0 ...\n",
       "  * i         (i) float64 1.0 2.0 3.0 4.0 5.0 6.0 7.0 8.0 9.0 10.0 11.0 12.0 ...\n",
       "    tim       (time) datetime64[ns] ...\n",
       "    timestep  (time) float64 ...\n",
       "    lon_c     (tile, j, i) float64 ...\n",
       "    lat_c     (tile, j, i) float64 ...\n",
       "  * tile      (tile) int64 1 2 3 4 5 6 7 8 9 10 11 12 13\n",
       "Data variables:\n",
       "    SSH       (time, tile, j, i) float64 ...\n",
       "    XC        (tile, j, i) float64 ...\n",
       "    YC        (tile, j, i) float64 ..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_subset_loaded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `equals` method does element-by-element comparison of `Dataset` and `DataArray` objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_subset.equals(data_subset_loaded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So nice to hear!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving a `DataArray`\n",
    "\n",
    "Let's save the *SSH* `DataArray` object inside *ssh_all_tiles*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving to  /Users/ifenty/ECCOv4/R3/nctiles_monthly/SSH/ssh_dataArray.nc\n",
      "finished saving\n"
     ]
    }
   ],
   "source": [
    "new_filename = data_dir + 'ssh_dataArray.nc'\n",
    "print 'saving to ', new_filename\n",
    "\n",
    "ssh_all_tiles.to_netcdf(path=new_filename)\n",
    "print 'finished saving'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the results of calculations\n",
    "\n",
    "### Calculations in the form of `DataArrays`\n",
    "Often we would like to store the results of our calculations to disk.  If your operations are made at the level of `DataArray` objects (and not the lower `ndarray` level) then you can use these same methods to save your results.  All of the coordinates will be preserved (although attributes be lost).  Let's demonstrate by making a dummy calculation on SSH\n",
    "\n",
    "$$SSH_{sq}(i) = SSH(i)^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.DataArray 'SSH' (time: 288, tile: 13, j: 90, i: 90)>\n",
       "array([[[[     nan, ...,      nan],\n",
       "         ...,\n",
       "         [2.200343, ..., 1.833477]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.508914, ...,      nan],\n",
       "         ...,\n",
       "         [2.147456, ...,      nan]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[     nan, ...,      nan],\n",
       "         ...,\n",
       "         [1.984065, ..., 1.741136]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.336955, ...,      nan],\n",
       "         ...,\n",
       "         [1.933404, ...,      nan]]]])\n",
       "Coordinates:\n",
       "  * time      (time) float64 1.0 2.0 3.0 4.0 5.0 6.0 7.0 8.0 9.0 10.0 11.0 ...\n",
       "  * j         (j) float64 1.0 2.0 3.0 4.0 5.0 6.0 7.0 8.0 9.0 10.0 11.0 12.0 ...\n",
       "  * i         (i) float64 1.0 2.0 3.0 4.0 5.0 6.0 7.0 8.0 9.0 10.0 11.0 12.0 ...\n",
       "    tim       (time) datetime64[ns] 1992-01-16 1992-02-16 1992-03-16 ...\n",
       "    timestep  (time) float64 732.0 1.428e+03 2.172e+03 2.892e+03 3.636e+03 ...\n",
       "    lon_c     (tile, j, i) float64 -111.6 -111.3 -110.9 -110.5 -110.0 -109.3 ...\n",
       "    lat_c     (tile, j, i) float64 -88.24 -88.38 -88.52 -88.66 -88.8 -88.94 ...\n",
       "  * tile      (tile) int64 1 2 3 4 5 6 7 8 9 10 11 12 13"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SSH_sq = data.SSH * data.SSH\n",
    "\n",
    "SSH_sq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*SSH_sq* is itself a `DataArray`.  If instead we had operated on the `numpy` arrays stored in data.SSH directly we would have been returned a `ndarray`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before saving, let's give our new *SSH_sq* variable a better name and descriptive attributes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.DataArray 'SSH^2' (time: 288, tile: 13, j: 90, i: 90)>\n",
       "array([[[[     nan, ...,      nan],\n",
       "         ...,\n",
       "         [2.200343, ..., 1.833477]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.508914, ...,      nan],\n",
       "         ...,\n",
       "         [2.147456, ...,      nan]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[     nan, ...,      nan],\n",
       "         ...,\n",
       "         [1.984065, ..., 1.741136]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.336955, ...,      nan],\n",
       "         ...,\n",
       "         [1.933404, ...,      nan]]]])\n",
       "Coordinates:\n",
       "  * time      (time) float64 1.0 2.0 3.0 4.0 5.0 6.0 7.0 8.0 9.0 10.0 11.0 ...\n",
       "  * j         (j) float64 1.0 2.0 3.0 4.0 5.0 6.0 7.0 8.0 9.0 10.0 11.0 12.0 ...\n",
       "  * i         (i) float64 1.0 2.0 3.0 4.0 5.0 6.0 7.0 8.0 9.0 10.0 11.0 12.0 ...\n",
       "    tim       (time) datetime64[ns] 1992-01-16 1992-02-16 1992-03-16 ...\n",
       "    timestep  (time) float64 732.0 1.428e+03 2.172e+03 2.892e+03 3.636e+03 ...\n",
       "    lon_c     (tile, j, i) float64 -111.6 -111.3 -110.9 -110.5 -110.0 -109.3 ...\n",
       "    lat_c     (tile, j, i) float64 -88.24 -88.38 -88.52 -88.66 -88.8 -88.94 ...\n",
       "  * tile      (tile) int64 1 2 3 4 5 6 7 8 9 10 11 12 13\n",
       "Attributes:\n",
       "    long_name:    Square of Surface Height Anomaly\n",
       "    units:        m^2\n",
       "    grid_layout:  original llc"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SSH_sq.name = 'SSH^2'\n",
    "SSH_sq.attrs['long_name'] = 'Square of Surface Height Anomaly'\n",
    "SSH_sq.attrs['units'] = 'm^2'\n",
    "SSH_sq.attrs['grid_layout'] = 'original llc'\n",
    "\n",
    "# Let's see the result\n",
    "SSH_sq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "much better!  Now we'll save."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving to  /Users/ifenty/ECCOv4/R3/nctiles_monthly/SSH/ssh_sq_DataArray.nc\n",
      "finished saving\n"
     ]
    }
   ],
   "source": [
    "new_filename = data_dir + 'ssh_sq_DataArray.nc'\n",
    "print 'saving to ', new_filename\n",
    "\n",
    "SSH_sq.to_netcdf(path=new_filename)\n",
    "print 'finished saving'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Calculations in the form of `numpy ndarrays`\n",
    "\n",
    "If calculations are made at the `ndarray` level then the results will also be `ndarrays`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SSH_dummy_ndarray = data.SSH.values *  data.SSH.values\n",
    "\n",
    "type(SSH_dummy_ndarray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll need to find different methods to save these results to NetCDF files, one of which is described here: http://pyhogs.github.io/intro_netcdf4.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Now you know how to save `Datasets` and `DataArrays` to disk as NetCDF!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

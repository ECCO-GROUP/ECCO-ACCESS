{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining multiple `Datasets` \n",
    "\n",
    "## Objectives:\n",
    "\n",
    "Show how to combine multiple ECCO v4 state estimate `Datasets` after loading.\n",
    "\n",
    "## Loading multiple `Datasets`  \n",
    "\n",
    "In previous tutorials we've loaded single lat-lon-cap NetCDF tile files for ECCO state estimate variables and model grid parameters.  Here we will demonstrate merging the resulting `Datasets` together.  Some benefits of merging `Datasets` include having a tidier workspace and simplying subsetting operations, the subject of a future tutorial.  \n",
    "\n",
    "First, we'll load three ECCOv4 NetCDF state estimate variables and the model grid.  For this exercise use the ECCOv4 NetCDF files in Format 2 (one NetCDF file corresponds to one variable and one year).  \n",
    "\n",
    "First let's define our environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import the ecco_v4_py library into Python\n",
    "## =========================================\n",
    "\n",
    "## -- For the ECCO Summer School, use \n",
    "import ecco_v4_py as ecco\n",
    "\n",
    "## -- If ecco_v4_py is not installed in your local Python library, \n",
    "##    tell Python where to find it.  For example, if your ecco_v4_py\n",
    "##    files are in /Users/ifenty/ECCOv4-py/ecco_v4_py, then use:\n",
    "\n",
    "# sys.path.append('/Users/ifenty/ECCOv4-py')\n",
    "# import ecco_v4_py as ecco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tell Python where to find some ECCO NetCDF \n",
    "## yearly-aggregated fields (Format 1)\n",
    "## ===================================\n",
    "\n",
    "## -- For the ECCO Summer School, use\n",
    "base_dir = '/work/projects/aci/ECCO/community/ECCO/ECCOv4/Release3p1'\n",
    "\n",
    "## -- If files are on a local machine, use something like \n",
    "#base_dir = '/Users/ifenty/'\n",
    "\n",
    "ECCO_dir = base_dir + '/eccov4r3_native_grid_netcdf/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *c* point: ``SSH``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function load_ecco_var_from_years_nc in module ecco_v4_py.tile_io:\n",
      "\n",
      "load_ecco_var_from_years_nc(data_dir, var_to_load, years_to_load='all', tiles_to_load='all', k_subset=[], dask_chunk=True, less_output=True)\n",
      "    Loads one or more ECCOv4 NetCDF state estimate variable in the\n",
      "    format of one file per variable per year.  All 13 tiles of the \n",
      "    lat-lon-cap (llc) grid are present in this type of file.\n",
      "    \n",
      "    Files in this format have names like \n",
      "        /eccov4r3_native_grid_netcdf/mon_mean/THETA_2010.nc\n",
      "        /eccov4r3_native_grid_netcdf/day_mean/THETA_2010.nc\n",
      "        /eccov4r3_native_grid_netcdf/mon_snapshot/THETA_2010.nc\n",
      "    \n",
      "    Simply point this routine at a directory with one or more \n",
      "    of these files and one or more years of var_to_load variables will\n",
      "    be loaded. \n",
      "    * Used repeatedly by recursive_load_ecco_var_from_years_nc *\n",
      "    \n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    data_dir : str\n",
      "        path to a directory within which we will look for NetCDF tile files\n",
      "    \n",
      "    var_to_load : str\n",
      "        string indicating which variable to load.\n",
      "        \n",
      "    years_to_load : str, int or list, optional, default 'all'\n",
      "        a list of which years to load.  \n",
      "    \n",
      "    k_subset : list, optional, default = [] (load all)\n",
      "        a list of which vertical levels to load. \n",
      "                \n",
      "    dask_chunk : boolean, optional, default True\n",
      "        whether or not to ask Dask to chunk the arrays into pieces 90x90.  \n",
      "        WARNING: DON'T MESS WITH THIS NUMBER.\n",
      "    \n",
      "    less_output : boolean, default False\n",
      "        A debugging flag.  False = less debugging output\n",
      "        \n",
      "    Returns\n",
      "    -------\n",
      "    g : Dataset\n",
      "        an xarray Dataset\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(ecco.load_ecco_var_from_years_nc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "SSH_dir= ECCO_dir + '/mon_mean/SSH/'  \n",
    "var = 'SSH'\n",
    "\n",
    "# make use of the ``load_ecco_var_from_years_nc`` routine to \n",
    "# load a single variable \n",
    "ecco_dataset_A = ecco.load_ecco_var_from_years_nc(SSH_dir, \\\n",
    "                                                  var, \\\n",
    "                                                  tiles_to_load=[0,1,2,3],\\\n",
    "                                                  years_to_load=[2010])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to see the data variables in a dataset, use ``.data_vars``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data variables:\n",
       "    SSH      (time, tile, j, i) float32 dask.array<shape=(12, 4, 90, 90), chunksize=(12, 4, 90, 90)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ecco_dataset_A.data_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, *ecco_dataset_A* has one ``data variable``, *SSH*, which has dimensions **i**, **j**, **tile**, and **time**.\n",
    "Its coordinates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Coordinates:\n",
       "  * j        (j) int32 0 1 2 3 4 5 6 7 8 9 10 ... 80 81 82 83 84 85 86 87 88 89\n",
       "  * i        (i) int32 0 1 2 3 4 5 6 7 8 9 10 ... 80 81 82 83 84 85 86 87 88 89\n",
       "    XC       (tile, j, i) float32 dask.array<shape=(4, 90, 90), chunksize=(4, 90, 90)>\n",
       "    YC       (tile, j, i) float32 dask.array<shape=(4, 90, 90), chunksize=(4, 90, 90)>\n",
       "    rA       (tile, j, i) float32 dask.array<shape=(4, 90, 90), chunksize=(4, 90, 90)>\n",
       "  * tile     (tile) int32 0 1 2 3\n",
       "    iter     (time) int32 dask.array<shape=(12,), chunksize=(12,)>\n",
       "  * time     (time) datetime64[ns] 2010-01-16T12:00:00 ... 2010-12-16T12:00:00"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ecco_dataset_A.SSH.coords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *u* point: ``ADVx_TH``\n",
    "\n",
    "``ADVx_TH`` is the horizontal advective flux of potential temperature in each tile's $x$ direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data variables:\n",
       "    ADVx_TH  (time, tile, k, j, i_g) float32 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ADVx_dir= ECCO_dir + '/mon_mean/ADVx_TH/'  \n",
    "var = 'ADVx_TH'\n",
    "\n",
    "# make use of the ``load_ecco_var_from_years_nc`` routine to \n",
    "# load a single variable \n",
    "ecco_dataset_B= ecco.load_ecco_var_from_years_nc(ADVx_dir, \\\n",
    "                                                 var, \\\n",
    "                                                 years_to_load=2010).load();\n",
    "ecco_dataset_B.attrs=[]\n",
    "\n",
    "ecco_dataset_B.data_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*ecco_dataset_A* has one ``data variable``, *ADVx_TH*, which has dimensions **i_g**, **j**, **k** **tile**, and **time**.  *ADVx_TH* is a three-dimensional field.\n",
    "\n",
    "Notice that the coordinates of *ecco_dataset_B* is distinct from *ecco_dataset_A*.  Specifically, *ecco_dataset_B* has a **k** dimension, and several new non-dimension coords such as **drF** and **dyG**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Coordinates:\n",
       "  * i_g        (i_g) int32 0 1 2 3 4 5 6 7 8 9 ... 80 81 82 83 84 85 86 87 88 89\n",
       "  * j          (j) int32 0 1 2 3 4 5 6 7 8 9 ... 80 81 82 83 84 85 86 87 88 89\n",
       "  * k          (k) int32 0 1 2 3 4 5 6 7 8 9 ... 40 41 42 43 44 45 46 47 48 49\n",
       "    Z          (k) float32 -5.0 -15.0 -25.0 -35.0 ... -5039.25 -5461.25 -5906.25\n",
       "    PHrefC     (k) float32 49.05 147.15 245.25 ... 49435.043 53574.863 57940.312\n",
       "    drF        (k) float32 10.0 10.0 10.0 10.0 10.0 ... 387.5 410.5 433.5 456.5\n",
       "    dxC        (tile, j, i_g) float32 15583.418 15588.104 ... 23406.256\n",
       "    rAw        (tile, j, i_g) float32 361699460.0 362790240.0 ... 364760350.0\n",
       "    dyG        (tile, j, i_g) float32 23210.262 23273.26 ... 15595.26 15583.685\n",
       "    hFacW      (tile, k, j, i_g) float32 0.0 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0\n",
       "  * tile       (tile) int32 0 1 2 3 4 5 6 7 8 9 10 11 12\n",
       "    time_bnds  (time, nv) datetime64[ns] 2010-01-01 2010-02-01 ... 2011-01-01\n",
       "    iter       (time) int32 158532 159204 159948 160668 ... 165084 165804 166548\n",
       "  * time       (time) datetime64[ns] 2010-01-16T12:00:00 ... 2010-12-16T12:00:00"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ecco_dataset_B.coords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *v* point: ``ADVy_TH``\n",
    "\n",
    "``ADVy_TH`` is the horizontal advective flux of potential temperature in each tile's $y$ direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data variables:\n",
       "    ADVy_TH  (time, tile, k, j_g, i) float32 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ADVy_dir= ECCO_dir + '/mon_mean/ADVy_TH/'  \n",
    "var = 'ADVy_TH'\n",
    "\n",
    "ecco_dataset_C= ecco.load_ecco_var_from_years_nc(ADVy_dir, \\\n",
    "                                                 var, \\\n",
    "                                                 years_to_load=2010).load();\n",
    "ecco_dataset_C.attrs=[]\n",
    "ecco_dataset_C.data_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*ecco_dataset_C* has one ``data variable``, *ADVy_TH*, which has dimensions **i**, **j_g**, **k** **tile**, and **time**.  *ADVy_TH* is a three-dimensional field."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examining the dimensions and coordinates of these `Datasets`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of our three `Datasets` contain a single  `DataArray`.  Each of these `DataArray` objects has different horizontal dimension labels.  \n",
    "\n",
    "* **i** and **j** for *SSH*\n",
    "* **i_g** and **j** for *ADVx_TH*\n",
    "* **i** and **j_g** for *ADVy_TH*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data variables:\n",
      "    SSH      (time, tile, j, i) float32 dask.array<shape=(12, 4, 90, 90), chunksize=(12, 4, 90, 90)>\n",
      "Data variables:\n",
      "    ADVx_TH  (time, tile, k, j, i_g) float32 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0\n",
      "Data variables:\n",
      "    ADVy_TH  (time, tile, k, j_g, i) float32 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0\n"
     ]
    }
   ],
   "source": [
    "print(ecco_dataset_A.data_vars)\n",
    "print(ecco_dataset_B.data_vars)\n",
    "print(ecco_dataset_C.data_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging multiple `Datasets`  from state estimate variables\n",
    "\n",
    "Using the `xarray` method ``merge`` we can create a single `Dataset` with multiple `DataArrays`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# merge together\n",
    "ecco_dataset_ABC = xr.merge([ecco_dataset_A, ecco_dataset_B, ecco_dataset_C]).load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examining the merged `Dataset`\n",
    "\n",
    "As before, let's look at the contents of the new merged `Dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:    (i: 90, i_g: 90, j: 90, j_g: 90, k: 50, nv: 2, tile: 13, time: 12)\n",
       "Coordinates:\n",
       "  * tile       (tile) int64 0 1 2 3 4 5 6 7 8 9 10 11 12\n",
       "  * j          (j) int32 0 1 2 3 4 5 6 7 8 9 ... 80 81 82 83 84 85 86 87 88 89\n",
       "  * i          (i) int32 0 1 2 3 4 5 6 7 8 9 ... 80 81 82 83 84 85 86 87 88 89\n",
       "    XC         (tile, j, i) float32 -111.60647 -111.303 -110.94285 ... nan nan\n",
       "    YC         (tile, j, i) float32 -88.24259 -88.382515 -88.52242 ... nan nan\n",
       "    rA         (tile, j, i) float32 362256450.0 363300960.0 ... nan nan\n",
       "    time_bnds  (time, nv) datetime64[ns] 2010-01-01 2010-02-01 ... 2011-01-01\n",
       "    iter       (time) int32 158532 159204 159948 160668 ... 165084 165804 166548\n",
       "  * time       (time) datetime64[ns] 2010-01-16T12:00:00 ... 2010-12-16T12:00:00\n",
       "  * i_g        (i_g) int32 0 1 2 3 4 5 6 7 8 9 ... 80 81 82 83 84 85 86 87 88 89\n",
       "  * k          (k) int32 0 1 2 3 4 5 6 7 8 9 ... 40 41 42 43 44 45 46 47 48 49\n",
       "    Z          (k) float32 -5.0 -15.0 -25.0 -35.0 ... -5039.25 -5461.25 -5906.25\n",
       "    PHrefC     (k) float32 49.05 147.15 245.25 ... 49435.043 53574.863 57940.312\n",
       "    drF        (k) float32 10.0 10.0 10.0 10.0 10.0 ... 387.5 410.5 433.5 456.5\n",
       "    dxC        (tile, j, i_g) float32 15583.418 15588.104 ... 23406.256\n",
       "    rAw        (tile, j, i_g) float32 361699460.0 362790240.0 ... 364760350.0\n",
       "    dyG        (tile, j, i_g) float32 23210.262 23273.26 ... 15595.26 15583.685\n",
       "    hFacW      (tile, k, j, i_g) float32 0.0 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0\n",
       "  * j_g        (j_g) int32 0 1 2 3 4 5 6 7 8 9 ... 80 81 82 83 84 85 86 87 88 89\n",
       "    rAs        (tile, j_g, i) float32 179944260.0 180486990.0 ... 364150620.0\n",
       "    dxG        (tile, j_g, i) float32 15584.907 15589.316 ... 23142.107\n",
       "    dyC        (tile, j_g, i) float32 11563.718 11593.785 ... 15578.138\n",
       "    hFacS      (tile, k, j_g, i) float32 0.0 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0\n",
       "Dimensions without coordinates: nv\n",
       "Data variables:\n",
       "    SSH        (time, tile, j, i) float32 0.0 0.0 0.0 0.0 ... nan nan nan nan\n",
       "    ADVx_TH    (time, tile, k, j, i_g) float32 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0\n",
       "    ADVy_TH    (time, tile, k, j_g, i) float32 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ecco_dataset_ABC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 1. Dimensions\n",
    "`Dimensions:   (i: 90, i_g: 90, j: 90, j_g: 90, k: 50, nv: 2, tile: 13, time: 12)`\n",
    "\n",
    "*ecco_dataset_merged* is a container of ``Data Arrays`` and as such it lists all of the unique dimensions its ``Data Arrays``. In other words, *Dimensions* shows all of the dimensions used by its variables. \n",
    "\n",
    "#### 2. Dimension Coordinates\n",
    "```\n",
    "Coordinates:\n",
    "Coordinates:\n",
    "  * j          (j) int32 0 1 2 3 4 5 6 7 8 9 ... 80 81 82 83 84 85 86 87 88 89\n",
    "  * i          (i) int32 0 1 2 3 4 5 6 7 8 9 ... 80 81 82 83 84 85 86 87 88 89\n",
    "  * tile       (tile) int32 0 1 2 3 4 5 6 7 8 9 10 11 12\n",
    "  * time       (time) datetime64[ns] 2010-01-16T12:00:00 ... 2010-12-16T12:00:00\n",
    "  * i_g        (i_g) int32 0 1 2 3 4 5 6 7 8 9 ... 80 81 82 83 84 85 86 87 88 89\n",
    "  * k          (k) int32 0 1 2 3 4 5 6 7 8 9 ... 40 41 42 43 44 45 46 47 48 49\n",
    "  * j_g        (j_g) int32 0 1 2 3 4 5 6 7 8 9 ... 80 81 82 83 84 85 86 87 88 89\n",
    "``` \n",
    "\n",
    "Notice that the **tile** and **time** coordinates are unchanged.  ``merge`` recognizes identical coordiantes and keeps them.\n",
    "\n",
    "#### 3. Non-Dimension Coordinates\n",
    "```\n",
    "Coordinates:\n",
    "    XC         (tile, j, i) float32 -111.60647 -111.303 ... -111.86579\n",
    "    YC         (tile, j, i) float32 -88.24259 -88.382515 ... -88.07871 -88.10267\n",
    "    rA         (tile, j, i) float32 362256450.0 363300960.0 ... 361119100.0\n",
    "    time_bnds  (time, nv) datetime64[ns] 2010-01-01 2010-02-01 ... 2011-01-01\n",
    "    iter       (time) int32 158532 159204 159948 160668 ... 165084 165804 166548\n",
    "    Z          (k) float32 -5.0 -15.0 -25.0 -35.0 ... -5039.25 -5461.25 -5906.25\n",
    "    PHrefC     (k) float32 49.05 147.15 245.25 ... 49435.043 53574.863 57940.312\n",
    "    drF        (k) float32 10.0 10.0 10.0 10.0 10.0 ... 387.5 410.5 433.5 456.5\n",
    "    dxC        (tile, j, i_g) float32 15583.418 15588.104 ... 23406.256\n",
    "    rAw        (tile, j, i_g) float32 361699460.0 362790240.0 ... 364760350.0\n",
    "    dyG        (tile, j, i_g) float32 23210.262 23273.26 ... 15595.26 15583.685\n",
    "    hFacW      (tile, k, j, i_g) float32 0.0 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0\n",
    "    rAs        (tile, j_g, i) float32 179944260.0 180486990.0 ... 364150620.0\n",
    "    dxG        (tile, j_g, i) float32 15584.907 15589.316 ... 23142.107\n",
    "    dyC        (tile, j_g, i) float32 11563.718 11593.785 ... 15578.138\n",
    "    hFacS      (tile, k, j_g, i) float32 0.0 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0\n",
    "```\n",
    "\n",
    "The list of non-dimension coordinates is now much longer.  Like *Dimensions*, the non-dimension coordinates of the merged ``Dataset`` contain all of the non-dimension coordinates of the ``Data Arrays``.\n",
    "\n",
    "\n",
    "#### 4. Attributes\n",
    "\n",
    "Notice that all of the high level `Dataset` attributes are gone!  Each of the three `Datasets` had different attributes and the `merge` routine simply drops them.  The attributes of the *Data variables* remain intact:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"long_name\": \"Surface Height Anomaly adjusted with global steric height change and sea-ice load\",\n",
      "  \"standard_name\": \"sea_surface_height\",\n",
      "  \"units\": \"m\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# (this json command makes Python dictionaries easier to read)\n",
    "print(json.dumps(ecco_dataset_ABC.SSH.attrs, indent=2,sort_keys=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding the model grid  `Dataset`\n",
    "\n",
    "Let's use the ``merge`` routine to combine a `Dataset` of the model grid parameters with `output_merged`.\n",
    "\n",
    "### Load the model grid parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Coordinates:\n",
       "  * i          (i) int64 0 1 2 3 4 5 6 7 8 9 ... 80 81 82 83 84 85 86 87 88 89\n",
       "  * i_g        (i_g) int64 0 1 2 3 4 5 6 7 8 9 ... 80 81 82 83 84 85 86 87 88 89\n",
       "  * j          (j) int64 0 1 2 3 4 5 6 7 8 9 ... 80 81 82 83 84 85 86 87 88 89\n",
       "  * j_g        (j_g) int64 0 1 2 3 4 5 6 7 8 9 ... 80 81 82 83 84 85 86 87 88 89\n",
       "  * k          (k) int64 0 1 2 3 4 5 6 7 8 9 ... 40 41 42 43 44 45 46 47 48 49\n",
       "  * k_u        (k_u) int64 0 1 2 3 4 5 6 7 8 9 ... 40 41 42 43 44 45 46 47 48 49\n",
       "  * k_l        (k_l) int64 0 1 2 3 4 5 6 7 8 9 ... 40 41 42 43 44 45 46 47 48 49\n",
       "  * k_p1       (k_p1) int64 0 1 2 3 4 5 6 7 8 9 ... 42 43 44 45 46 47 48 49 50\n",
       "  * tile       (tile) int64 0 1 2 3 4 5 6 7 8 9 10 11 12\n",
       "    XC         (tile, j, i) float32 ...\n",
       "    YC         (tile, j, i) float32 ...\n",
       "    XG         (tile, j_g, i_g) float32 ...\n",
       "    YG         (tile, j_g, i_g) float32 ...\n",
       "    CS         (tile, j, i) float32 ...\n",
       "    SN         (tile, j, i) float32 ...\n",
       "    Z          (k) float32 ...\n",
       "    Zp1        (k_p1) float32 ...\n",
       "    Zu         (k_u) float32 ...\n",
       "    Zl         (k_l) float32 ...\n",
       "    rA         (tile, j, i) float32 ...\n",
       "    dxG        (tile, j_g, i) float32 ...\n",
       "    dyG        (tile, j, i_g) float32 ...\n",
       "    Depth      (tile, j, i) float32 ...\n",
       "    rAz        (tile, j_g, i_g) float32 ...\n",
       "    dxC        (tile, j, i_g) float32 ...\n",
       "    dyC        (tile, j_g, i) float32 ...\n",
       "    rAw        (tile, j, i_g) float32 ...\n",
       "    rAs        (tile, j_g, i) float32 ...\n",
       "    drC        (k_p1) float32 ...\n",
       "    drF        (k) float32 ...\n",
       "    PHrefC     (k) float32 ...\n",
       "    PHrefF     (k_p1) float32 ...\n",
       "    hFacC      (k, tile, j, i) float32 ...\n",
       "    hFacW      (k, tile, j, i_g) float32 ...\n",
       "    hFacS      (k, tile, j_g, i) float32 ...\n",
       "    maskC      (k, tile, j, i) bool ...\n",
       "    maskW      (k, tile, j, i_g) bool ...\n",
       "    maskS      (k, tile, j_g, i) bool ...\n",
       "    maskCtrlW  (k, tile, j, i_g) bool ...\n",
       "    maskCtrlS  (k, tile, j_g, i) bool ...\n",
       "    maskCtrlC  (k, tile, j, i) bool ..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the llc90 grid parameters\n",
    "grid_dir= ECCO_dir + '/grid'\n",
    "grid_dataset = xr.open_dataset(grid_dir + '/ECCOv4r3_grid.nc')\n",
    "grid_dataset.coords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge ``grid_all_tiles`` with ``output_merged``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:    (i: 90, i_g: 90, j: 90, j_g: 90, k: 50, k_l: 50, k_p1: 51, k_u: 50, nv: 2, tile: 13, time: 12)\n",
       "Coordinates:\n",
       "  * tile       (tile) int64 0 1 2 3 4 5 6 7 8 9 10 11 12\n",
       "  * j          (j) int32 0 1 2 3 4 5 6 7 8 9 ... 80 81 82 83 84 85 86 87 88 89\n",
       "  * i          (i) int32 0 1 2 3 4 5 6 7 8 9 ... 80 81 82 83 84 85 86 87 88 89\n",
       "    XC         (tile, j, i) float32 -111.60647 -111.303 ... -111.86579\n",
       "    YC         (tile, j, i) float32 -88.24259 -88.382515 ... -88.07871 -88.10267\n",
       "    rA         (tile, j, i) float32 362256450.0 363300960.0 ... 361119100.0\n",
       "    time_bnds  (time, nv) datetime64[ns] 2010-01-01 2010-02-01 ... 2011-01-01\n",
       "    iter       (time) int32 158532 159204 159948 160668 ... 165084 165804 166548\n",
       "  * time       (time) datetime64[ns] 2010-01-16T12:00:00 ... 2010-12-16T12:00:00\n",
       "  * i_g        (i_g) int32 0 1 2 3 4 5 6 7 8 9 ... 80 81 82 83 84 85 86 87 88 89\n",
       "  * k          (k) int32 0 1 2 3 4 5 6 7 8 9 ... 40 41 42 43 44 45 46 47 48 49\n",
       "    Z          (k) float32 -5.0 -15.0 -25.0 -35.0 ... -5039.25 -5461.25 -5906.25\n",
       "    PHrefC     (k) float32 49.05 147.15 245.25 ... 49435.043 53574.863 57940.312\n",
       "    drF        (k) float32 10.0 10.0 10.0 10.0 10.0 ... 387.5 410.5 433.5 456.5\n",
       "    dxC        (tile, j, i_g) float32 15583.418 15588.104 ... 23406.256\n",
       "    rAw        (tile, j, i_g) float32 361699460.0 362790240.0 ... 364760350.0\n",
       "    dyG        (tile, j, i_g) float32 23210.262 23273.26 ... 15595.26 15583.685\n",
       "    hFacW      (tile, k, j, i_g) float32 0.0 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0\n",
       "  * j_g        (j_g) int32 0 1 2 3 4 5 6 7 8 9 ... 80 81 82 83 84 85 86 87 88 89\n",
       "    rAs        (tile, j_g, i) float32 179944260.0 180486990.0 ... 364150620.0\n",
       "    dxG        (tile, j_g, i) float32 15584.907 15589.316 ... 23142.107\n",
       "    dyC        (tile, j_g, i) float32 11563.718 11593.785 ... 15578.138\n",
       "    hFacS      (tile, k, j_g, i) float32 0.0 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0\n",
       "  * k_u        (k_u) int64 0 1 2 3 4 5 6 7 8 9 ... 40 41 42 43 44 45 46 47 48 49\n",
       "  * k_l        (k_l) int64 0 1 2 3 4 5 6 7 8 9 ... 40 41 42 43 44 45 46 47 48 49\n",
       "  * k_p1       (k_p1) int64 0 1 2 3 4 5 6 7 8 9 ... 42 43 44 45 46 47 48 49 50\n",
       "    XG         (tile, j_g, i_g) float32 ...\n",
       "    YG         (tile, j_g, i_g) float32 ...\n",
       "    CS         (tile, j, i) float32 ...\n",
       "    SN         (tile, j, i) float32 ...\n",
       "    Zp1        (k_p1) float32 ...\n",
       "    Zu         (k_u) float32 ...\n",
       "    Zl         (k_l) float32 ...\n",
       "    Depth      (tile, j, i) float32 ...\n",
       "    rAz        (tile, j_g, i_g) float32 ...\n",
       "    drC        (k_p1) float32 ...\n",
       "    PHrefF     (k_p1) float32 ...\n",
       "    hFacC      (k, tile, j, i) float32 ...\n",
       "    maskC      (k, tile, j, i) bool ...\n",
       "    maskW      (k, tile, j, i_g) bool ...\n",
       "    maskS      (k, tile, j_g, i) bool ...\n",
       "    maskCtrlW  (k, tile, j, i_g) bool ...\n",
       "    maskCtrlS  (k, tile, j_g, i) bool ...\n",
       "    maskCtrlC  (k, tile, j, i) bool ...\n",
       "Dimensions without coordinates: nv\n",
       "Data variables:\n",
       "    SSH        (time, tile, j, i) float32 0.0 0.0 0.0 0.0 ... nan nan nan nan\n",
       "    ADVx_TH    (time, tile, k, j, i_g) float32 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0\n",
       "    ADVy_TH    (time, tile, k, j_g, i) float32 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ecco_dataset_ABCG= xr.merge([ecco_dataset_ABC, grid_dataset])\n",
    "ecco_dataset_ABCG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examining the merged `Dataset`\n",
    "\n",
    "The result of this last merge is a single `Dataset` with 3 *Data variables*, and a complete set of model grid parameters (distances and areas).\n",
    "\n",
    "## Merging and memory\n",
    "\n",
    "Merging `Datasets` together does not make copies of the data in memory.  Instead, merged `Datasets` are in fact just a reorganized collection of pointers.  You may want to delete the original variables to clear your namespace, but it is not necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Now you know how to merge multiple `Datasets` using the `merge` command.  We demonstrated merging of `Datasets` constructed from three different variables types and the model grid parameters."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
